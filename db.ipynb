{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fe1b04c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in n:\\wisetwin\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in n:\\wisetwin\\.venv\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in n:\\wisetwin\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in n:\\wisetwin\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in n:\\wisetwin\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in n:\\wisetwin\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in n:\\wisetwin\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in n:\\wisetwin\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: psycopg2-binary in n:\\wisetwin\\.venv\\lib\\site-packages (2.9.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install tqdm\n",
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e73f5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Sync errors\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'    # Detailed asserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e88b93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid5, UUID\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8ca18d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in n:\\wisetwin\\.venv\\lib\\site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in n:\\wisetwin\\.venv\\lib\\site-packages (from dotenv) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d15e225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ec41606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in n:\\wisetwin\\.venv\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in n:\\wisetwin\\.venv\\lib\\site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in n:\\wisetwin\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in n:\\wisetwin\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in n:\\wisetwin\\.venv\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in n:\\wisetwin\\.venv\\lib\\site-packages (from openai) (2.12.5)\n",
      "Requirement already satisfied: sniffio in n:\\wisetwin\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in n:\\wisetwin\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in n:\\wisetwin\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in n:\\wisetwin\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in n:\\wisetwin\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in n:\\wisetwin\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in n:\\wisetwin\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in n:\\wisetwin\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in n:\\wisetwin\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in n:\\wisetwin\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in n:\\wisetwin\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in n:\\wisetwin\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48c7dc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('c87c53d6-4464-4018-b4c9-15718d354ec8')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UUID_NAMESPACE = UUID(\"c87c53d6-4464-4018-b4c9-15718d354ec8\")\n",
    "UUID_NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04ec38",
   "metadata": {},
   "source": [
    "# ARIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e0bbe1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62726 entries, 0 to 62725\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Titre                 62726 non-null  object\n",
      " 1   Type de publication   62726 non-null  object\n",
      " 2   Date                  62726 non-null  object\n",
      " 3   Num√©ro ARIA           62726 non-null  int64 \n",
      " 4   Code NAF              62721 non-null  object\n",
      " 5   Pays                  62720 non-null  object\n",
      " 6   D√©partment            62713 non-null  object\n",
      " 7   Commune               62674 non-null  object\n",
      " 8   Type d'accident       60066 non-null  object\n",
      " 9   Type √©v√®nement        61419 non-null  object\n",
      " 10  Mati√®res              58407 non-null  object\n",
      " 11  Equipements           34682 non-null  object\n",
      " 12  Classe de danger CLP  54671 non-null  object\n",
      " 13  Causes profondes      28440 non-null  object\n",
      " 14  Causes premi√®res      33866 non-null  object\n",
      " 15  Cons√©quences          58095 non-null  object\n",
      " 16  Echelle               62726 non-null  object\n",
      " 17  URL                   62726 non-null  object\n",
      " 18  Contenu               62726 non-null  object\n",
      "dtypes: int64(1), object(18)\n",
      "memory usage: 9.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./accidents-tous-req10905.csv\", encoding=\"cp1252\", sep=\";\", skiprows=7)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "79c9f012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Titre  \\\n",
      "0  Feu d'un b√¢timent d?exp√©dition de marchandises   \n",
      "\n",
      "             Type de publication        Date  Num√©ro ARIA  \\\n",
      "0  Accident avec fiche d√©taill√©e  2022/06/20        58245   \n",
      "\n",
      "                  Code NAF    Pays D√©partment  Commune Type d'accident  \\\n",
      "0  Entreposage et stockage  FRANCE         71  CRISSEY              IC   \n",
      "\n",
      "            Type √©v√®nement                                           Mati√®res  \\\n",
      "0  Rejet prolong√©,Incendie  [A-D003-4331] LIQUIDES INFLAMMABLES CLASSES RU...   \n",
      "\n",
      "                                         Equipements  \\\n",
      "0  Moyens d'extinction fixes (ria, poteau, sprink...   \n",
      "\n",
      "              Classe de danger CLP  \\\n",
      "0  Carc. 1A,Flam. Liq. 2,STOT SE 3   \n",
      "\n",
      "                                 Causes profondes  \\\n",
      "0  Identification des risques,Ergonomie inadapt√©e   \n",
      "\n",
      "                                Causes premi√®res  \\\n",
      "0  Danger latent,D√©fauts mat√©riels,Non effectu√©e   \n",
      "\n",
      "                                        Cons√©quences           Echelle  \\\n",
      "0  CONS√âQUENCES √âCONOMIQUES,Dommages mat√©riels in...  0H, 0En, 4Ec, 1M   \n",
      "\n",
      "                                                 URL  \\\n",
      "0  https://www.aria.developpement-durable.gouv.fr...   \n",
      "\n",
      "                                             Contenu  \n",
      "0  Vers 10¬†h un samedi, un feu se d√©clare dans un...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "44642c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 8949.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_to_db(df : pd.DataFrame, trunc = None):    \n",
    "\n",
    "    if trunc is not None :\n",
    "        df = df.head(trunc)\n",
    "\n",
    "    def create_line(line : pd.Series):\n",
    "        address = \" \".join([str(line[\"D√©partment\"]), str(line[\"Commune\"])])\n",
    "        site_id = str(uuid5(UUID_NAMESPACE, address))\n",
    "        sites = {\n",
    "            \"site_id\" : site_id,\n",
    "            \"plant_name\": \"\",\n",
    "            \"address\": address,\n",
    "            \"latitude\": None,               # to fill later\n",
    "            \"longitude\": None,              # to fill later\n",
    "            \"country\": line[\"Pays\"],\n",
    "            \"industrial_activity\": line[\"Code NAF\"],\n",
    "        }\n",
    "\n",
    "        accident_key = \" \".join([str(line[\"Titre\"]), str(line[\"Date\"])])\n",
    "        accident_id = str(uuid5(UUID_NAMESPACE, accident_key))\n",
    "        accidents = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"site_id\": site_id,\n",
    "            \"title\": line[\"Titre\"],\n",
    "            \"source\": \"ARIA\",\n",
    "            \"source_id\": str(line[\"Num√©ro ARIA\"]),\n",
    "            \"accident_date\": line[\"Date\"],\n",
    "            \"severity_scale\": line[\"Echelle\"],\n",
    "            \"raw_data\": \"\", #line,\n",
    "            \"created_at\": \"date.now()\",\n",
    "            \"updated_at\": \"\",\n",
    "        }\n",
    "\n",
    "        causes = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"event_category\": line[\"Causes profondes\"],\n",
    "            \"failure\": line[\"Causes premi√®res\"],\n",
    "            \"description\": line[\"Contenu\"], # could also reuse Contenu\n",
    "        }\n",
    "\n",
    "        substances = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"name\": line[\"Mati√®res\"],\n",
    "            \"cas_number\": \"\",\n",
    "            \"quantity\": \"\",\n",
    "            \"clp_class\" : line[\"Classe de danger CLP\"]\n",
    "        }\n",
    "\n",
    "        consequences_human = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"fatalities\": None,\n",
    "            \"injuries\": None,\n",
    "            \"evacuated\": None,\n",
    "            \"hospitalized\": None,\n",
    "        }\n",
    "\n",
    "        consequences = {\n",
    "            \"ENVIRONNEMENTALES\" : \"\",\n",
    "            \"√âCONOMIQUES\" : \"\"\n",
    "        }\n",
    "\n",
    "        try :\n",
    "            for consequence in line[\"Cons√©quences\"].split(\"CONS√âQUENCES \"):\n",
    "                if len(consequence) < 2 : continue\n",
    "                s = consequence.split(',')\n",
    "                key = s[0]\n",
    "                content = (','.join(s[1:])).removesuffix(',')\n",
    "                consequences[key] = content\n",
    "        except : pass\n",
    "\n",
    "        consequences_other = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"environmental_impact\": consequences[\"ENVIRONNEMENTALES\"],\n",
    "            \"economic_cost\": consequences[\"√âCONOMIQUES\"],\n",
    "            \"disruption_duration\": line[\"Type √©v√®nement\"]\n",
    "        }\n",
    "\n",
    "        tables = {\n",
    "            \"sites\": sites,\n",
    "            \"accidents\": accidents,\n",
    "            \"causes\": causes,\n",
    "            \"substances\": substances,\n",
    "            \"consequences_human\": consequences_human,\n",
    "            \"consequences_other\": consequences_other\n",
    "        }\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    db_lines = []\n",
    "\n",
    "    for x in tqdm(iter(df.iloc), total=trunc, ncols=200):\n",
    "        db_lines.append(create_line(x))\n",
    "\n",
    "    return db_lines\n",
    "\n",
    "ARIA_db_jsons = convert_to_db(df, trunc=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3eac30ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ========================================================================================================================================================================================================\n",
      "sites"
     ]
    },
    {
     "data": {
      "application/json": {
       "address": "71 CRISSEY",
       "country": "FRANCE",
       "industrial_activity": "Entreposage et stockage",
       "latitude": null,
       "longitude": null,
       "plant_name": "",
       "site_id": "9da311e8-83b8-5139-8fcf-3f32cef9ae8a"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accidents"
     ]
    },
    {
     "data": {
      "application/json": {
       "accident_date": "2022/06/20",
       "accident_id": "2f15d13b-a13a-5c3b-86ea-a80d6ba28e5b",
       "created_at": "date.now()",
       "raw_data": "",
       "severity_scale": "0H, 0En, 4Ec, 1M",
       "site_id": "9da311e8-83b8-5139-8fcf-3f32cef9ae8a",
       "source": "ARIA",
       "source_id": "58245",
       "title": "Feu d'un b√¢timent d?exp√©dition de marchandises",
       "updated_at": ""
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causes"
     ]
    },
    {
     "data": {
      "application/json": {
       "accident_id": "2f15d13b-a13a-5c3b-86ea-a80d6ba28e5b",
       "description": "Vers 10¬†h un samedi, un feu se d√©clare dans un b√¢timent d'exp√©dition de marchandises d'une surface de 6¬†000¬†m¬≤ au sein d'une entreprise sp√©cialis√©e dans le fret. Un important panache de fum√©e se d√©gage et des bruits d'explosion se font entendre. Un p√©rim√®tre de s√©curit√© est mis en place et 4 habitations se situant √† proximit√© du sinistre sont confin√©es par mesure de s√©curit√©. La circulation est coup√©e et d√©vi√©e sur la D5. Le feu se propage √† certains v√©hicules stationn√©s √† proximit√©. Il est circonscrit et ma√Ætris√© par les pompiers √† 13h10 permettant la sauvegarde du b√¢timent administratif et de l'ensemble des serveurs informatiques. Les b√¢timents pr√©sentant le plus fort potentiel de risque (en raison du stockage de mati√®res dangereuses) n'ont pas √©t√© impact√©s. Les op√©rations de noyage se poursuivent jusqu'au lendemain. Les eaux d'extinction sont retenues dans des bacs de r√©tention. Des premi√®res mesures atmosph√©riques ne montrent pas d'impact particulier du sinistre.Le b√¢timent de messagerie est effondr√©. Celui-ci construit l'ann√©e pr√©c√©dente, comprenait une centaine de quais de d√©chargement et contenait des colis √† livrer repr√©sentant plus de 250¬†t de mati√®res dont 3,7 class√©es mati√®res dangereuses (comprenant notamment des liquides inflammables). 22 porteurs de 12¬†t et 7¬†remorques poids lourds ont √©t√© d√©truits. Le co√ªt du sinistre est estim√© √† 15¬†millions d'euros. 40¬†personnes sont au ch√¥mage technique.Le d√©part de feu serait d√ª √† un probl√®me au niveau d'une batterie au lithium d'un transpalette (choc sur la batterie ou ou√Øes du chargeur obstru√©es). Les premiers √©l√©ments tendent √† montrer que la d√©fense incendie du site √©tait insuffisante avec notamment l'absence de point d'eau au nord du b√¢timent.√Ä la suite de l'√©v√©nement, un arr√™t√© pr√©fectoral de mesures d'urgence est pris afin d'encadrer notamment, la gestion des d√©chets et des eaux d'extinction et de prescrire une mod√©lisation du panache de fum√©es. Les conditions de reprise de l'activit√© messagerie sont √©galement pr√©cis√©es.Pour la reconstruction du b√¢timent, l'exploitant envisage¬†:de modifier la d√©tection incendie (sir√®ne, lev√©e de doute)¬†;de mettre en place une protection sprinkler sur le b√¢timent,de modifier son POI (int√©gration du b√¢timent, modification de la gestion des cl√©s des camions)¬†;d'am√©nager un local de charge adapt√© pour les batteries lithium-ion.",
       "event_category": "Identification des risques,Ergonomie inadapt√©e",
       "failure": "Danger latent,D√©fauts mat√©riels,Non effectu√©e"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substances"
     ]
    },
    {
     "data": {
      "application/json": {
       "accident_id": "2f15d13b-a13a-5c3b-86ea-a80d6ba28e5b",
       "cas_number": "",
       "clp_class": "Carc. 1A,Flam. Liq. 2,STOT SE 3",
       "name": "[A-D003-4331] LIQUIDES INFLAMMABLES CLASSES RUBRIQUE 4331,[A-M069] BOIS (INCLUS SCIURE, COPEAU, LIEGE, PATE‚Ä¶),[A-M007] CARTON,[A-M089] PAPIER (DONT PATE A PAPIER‚Ä¶)",
       "quantity": ""
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consequences_human"
     ]
    },
    {
     "data": {
      "application/json": {
       "accident_id": "2f15d13b-a13a-5c3b-86ea-a80d6ba28e5b",
       "evacuated": null,
       "fatalities": null,
       "hospitalized": null,
       "injuries": null
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consequences_other"
     ]
    },
    {
     "data": {
      "application/json": {
       "accident_id": "2f15d13b-a13a-5c3b-86ea-a80d6ba28e5b",
       "disruption_duration": "Rejet prolong√©,Incendie",
       "economic_cost": "Dommages mat√©riels internes",
       "environmental_impact": "Type d'atteinte au milieu,air"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import JSON, display\n",
    "\n",
    "def print_db_jsons(json):\n",
    "    for i, db_line in enumerate(json):\n",
    "        print(i, \"=\" * 200)\n",
    "        for key in db_line :\n",
    "            print(key, flush=True, end='')\n",
    "            display(JSON(db_line[key], expanded=True))\n",
    "        if i == 0 : break\n",
    "\n",
    "print_db_jsons(ARIA_db_jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0156a",
   "metadata": {},
   "source": [
    "# OSHA - Injuries (ITA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c5110c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_18652\\2963357071.py:1: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./ITA Case Detail Data 2024 through 08-31-2025.csv\", sep=\",\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 686806 entries, 0 to 686805\n",
      "Data columns (total 39 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   id                        686806 non-null  int64  \n",
      " 1   establishment_id          686806 non-null  int64  \n",
      " 2   establishment_name        686806 non-null  object \n",
      " 3   ein                       626651 non-null  float64\n",
      " 4   company_name              650723 non-null  object \n",
      " 5   street_address            686806 non-null  object \n",
      " 6   city                      686806 non-null  object \n",
      " 7   state                     686806 non-null  object \n",
      " 8   zip_code                  686806 non-null  int64  \n",
      " 9   naics_code                686806 non-null  int64  \n",
      " 10  naics_year                686806 non-null  int64  \n",
      " 11  industry_description      634366 non-null  object \n",
      " 12  establishment_type        685782 non-null  float64\n",
      " 13  size                      686806 non-null  int64  \n",
      " 14  annual_average_employees  686806 non-null  int64  \n",
      " 15  total_hours_worked        686806 non-null  int64  \n",
      " 16  case_number               686798 non-null  object \n",
      " 17  job_description           685823 non-null  object \n",
      " 18  soc_code                  686805 non-null  object \n",
      " 19  soc_description           686805 non-null  object \n",
      " 20  soc_reviewed              686805 non-null  float64\n",
      " 21  soc_probability           686805 non-null  float64\n",
      " 22  date_of_incident          686798 non-null  object \n",
      " 23  incident_outcome          686806 non-null  int64  \n",
      " 24  dafw_num_away             686806 non-null  int64  \n",
      " 25  djtr_num_tr               686806 non-null  int64  \n",
      " 26  type_of_incident          686806 non-null  int64  \n",
      " 27  time_started_work         611380 non-null  object \n",
      " 28  time_of_incident          621521 non-null  object \n",
      " 29  time_unknown              685625 non-null  float64\n",
      " 30  date_of_death             199 non-null     object \n",
      " 31  created_timestamp         686806 non-null  object \n",
      " 32  year_filing_for           686806 non-null  int64  \n",
      " 33  NEW_NAR_WHAT_HAPPENED     686115 non-null  object \n",
      " 34  NEW_NAR_BEFORE_INCIDENT   685700 non-null  object \n",
      " 35  NEW_INCIDENT_LOCATION     686583 non-null  object \n",
      " 36  NEW_NAR_INJURY_ILLNESS    686246 non-null  object \n",
      " 37  NEW_NAR_OBJECT_SUBSTANCE  680096 non-null  object \n",
      " 38  NEW_INCIDENT_DESCRIPTION  686161 non-null  object \n",
      "dtypes: float64(5), int64(13), object(21)\n",
      "memory usage: 204.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./ITA Case Detail Data 2024 through 08-31-2025.csv\", sep=\",\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70bac5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  establishment_id                  establishment_name          ein  \\\n",
      "0  903263            858641  Lutheran Home of the Good Shepherd  450277267.0   \n",
      "\n",
      "                         company_name           street_address          city  \\\n",
      "0  Lutheran Home of the Good Shepherd  LHGS, 1226 1st Avenue N  New Rockford   \n",
      "\n",
      "  state  zip_code  naics_code  ...  time_unknown date_of_death  \\\n",
      "0    ND     58356      623110  ...           1.0           NaN   \n",
      "\n",
      "   created_timestamp  year_filing_for  \\\n",
      "0   01JAN25:15:23:00             2024   \n",
      "\n",
      "                       NEW_NAR_WHAT_HAPPENED  NEW_NAR_BEFORE_INCIDENT  \\\n",
      "0  Contact with [REDACTED] Positive Resident                  unknown   \n",
      "\n",
      "                  NEW_INCIDENT_LOCATION NEW_NAR_INJURY_ILLNESS  \\\n",
      "0  LHGS- contact with positive resident  Respiratory Condition   \n",
      "\n",
      "  NEW_NAR_OBJECT_SUBSTANCE NEW_INCIDENT_DESCRIPTION  \n",
      "0                    Covid               [REDACTED]  \n",
      "\n",
      "[1 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca3dbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(df : pd.DataFrame, trunc = None):    \n",
    "\n",
    "    if trunc is not None :\n",
    "        df = df.head(trunc)\n",
    "\n",
    "    def create_line(line : pd.Series):\n",
    "        address = f\"{line['street_address']} {line['city']} {line['state']} {line['zip_code']}\"\n",
    "        site_key = line[\"establishment_name\"] + \" \" + address\n",
    "        site_id = str(uuid5(UUID_NAMESPACE, site_key))\n",
    "        sites = {\n",
    "            \"site_id\" : site_id,\n",
    "            \"plant_name\": line[\"establishment_name\"],  # or fallback to \"company_name\"\n",
    "            \"address\": address,\n",
    "            \"latitude\": None,  # Geocode later from address\n",
    "            \"longitude\": None,\n",
    "            \"country\": \"USA\",\n",
    "            \"industrial_activity\": str(line[\"naics_code\"]),  # Maps to NAF equivalent\n",
    "        }\n",
    "\n",
    "        accident_key = \" \".join([line[\"job_description\"], line[\"date_of_incident\"]])\n",
    "        accident_id = str(uuid5(UUID_NAMESPACE, accident_key))\n",
    "        accidents = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"site_id\": site_id,\n",
    "            \"title\": line[\"job_description\"],  # Brief incident summary\n",
    "            \"source\": \"OSHA ITA\",\n",
    "            \"source_id\": line[\"case_number\"],  # Unique OSHA case identifier\n",
    "            \"accident_date\": line[\"date_of_incident\"],\n",
    "            \"severity_scale\": int(line[\"incident_outcome\"]),  # 1 = Death / 2 = Days away from work / 3 = Job transfer or restriction / 4 = Other recordable case\n",
    "            \"raw_data\": \"\",# line.to_dict(),  # Full line as JSON\n",
    "            \"created_at\": \"date.now()\",\n",
    "            \"updated_at\": \"\",  # Fill on save\n",
    "        }\n",
    "\n",
    "        causes = {\n",
    "            \"accident_id\": accident_id, \n",
    "            \"event_category\": line[\"NEW_NAR_WHAT_HAPPENED\"],  # Deep/root causes\n",
    "            \"equipment_failure\": line[\"NEW_NAR_BEFORE_INCIDENT\"],  # Initial triggers\n",
    "            \"description\": line[\"NEW_INCIDENT_DESCRIPTION\"],\n",
    "        }\n",
    "\n",
    "        substances = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"name\": line[\"NEW_NAR_OBJECT_SUBSTANCE\"],  # Object/substance hit/contacted\n",
    "            \"cas_number\": \"\",  # Not in ITA; research via name if needed\n",
    "            \"quantity\": \"\",  # Derive from context if available\n",
    "            \"clp_class\": line[\"NEW_NAR_INJURY_ILLNESS\"],  # Injury type as hazard proxy\n",
    "        }\n",
    "\n",
    "        consequences_human = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"fatalities\": 1 if pd.notna(line[\"date_of_death\"]) else 0,\n",
    "            \"injuries\": 1,  # Each line is one recordable case\n",
    "            \"evacuated\": None,  # Not directly available\n",
    "            \"hospitalized\": 1 if line[\"dafw_num_away\"] > 0 else 0,  # Days away implies severity\n",
    "        }\n",
    "\n",
    "        consequences_other = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"environmental_impact\": \"\",  # ITA focuses on worker injuries\n",
    "            \"economic_cost\": \"\",  # Estimate from total_hours_worked if needed\n",
    "            \"disruption_duration\": int(line[\"djtr_num_tr\"]),  # Restriction days as proxy\n",
    "        }\n",
    "\n",
    "        tables = {\n",
    "            \"sites\": sites,\n",
    "            \"accidents\": accidents,\n",
    "            \"causes\": causes,\n",
    "            \"substances\": substances,\n",
    "            \"consequences_human\": consequences_human,\n",
    "            \"consequences_other\": consequences_other\n",
    "        }\n",
    "\n",
    "        # taken_cols = [\"Titre\", \"Pays\", \"Code NAF\", \"Num√©ro ARIA\", \"Date\", \"Echelle\", \"Causes profondes\", \"Causes premi√®res\", \"Contenu\", \"Mati√®res\", \"Cons√©quences\", \"D√©partment\", \"Commune\", \"Classe de danger CLP\", \"Type √©v√®nement\"]\n",
    "        # print(line.drop(labels=taken_cols, errors='ignore'))\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    db_lines = []\n",
    "\n",
    "    if trunc is None:\n",
    "        itr = iter(df.iloc)\n",
    "    else :\n",
    "        itr = iter(df.head(trunc).iloc)\n",
    "\n",
    "    for x in tqdm(itr, total=5, ncols=200):\n",
    "        db_lines.append(create_line(x))\n",
    "\n",
    "    return db_lines\n",
    "\n",
    "# OSHA_db_jsons = convert_to_db(df, trunc=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e68534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_db_jsons(OSHA_db_jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6272fc4",
   "metadata": {},
   "source": [
    "# EPICEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "304a6a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "676"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epicea_example = {\n",
    "    \"Num√©ro du dossier\": \"27615\",\n",
    "    \"Comit√© technique national\": \"B - B√¢timent et Travaux Publics\",\n",
    "    \"Code entreprise\": \"4321A - Travaux d'installation √©lectrique dans tous locaux\",\n",
    "    \"Mat√©riel en cause\": \"270302 - Chaudi√®re √† mazout\",\n",
    "    \"R√©sum√© de l'accident\": r\"Une √©quipe de trois salari√©s dont un plombier chauffagiste, √¢g√© de 30 ans, intervient chez un particulier, un v√©t√©rinaire dont l'habitation se compose d'une maison et d'un bloc op√©ratoire (achet√©e il y a 21 ans auparavant, maison construite dans les ann√©es 70). L'installation de chauffage de l'habitation, compos√©e d‚Äôune pompe √† chaleur et d‚Äôune chaudi√®re au fioul, alimente les 28 radiateurs de la propri√©t√©. L'alimentation en eau chaude est assur√©e par un ballon d'eau ind√©pendant de l'installation de chauffage. Une chaudi√®re au fioul de la marque *** est plac√©e dans un local √† proximit√© de l'habitation. La chaudi√®re fonctionne en relai de la pompe √† chaleur. Quand la pompe n'arrive plus √† maintenir la consigne de temp√©rature, la chaudi√®re au fioul fonctionne (le propri√©taire de l‚Äôinstallation ne dispose pas du manuel d'utilisation ou d'installation de la chaudi√®re). Le propri√©taire rencontre des difficult√©s sur le fonctionnement de la chaudi√®re au fioul mais ne valide pas le premier devis pour la remplacer. Le second devis propose une remise en √©tat de la chaudi√®re existante avec un d√©sembouage des radiateurs, le remplacement des vannes des radiateurs, l'alimentation entre la cuve de fioul et la chaudi√®re et le ramonage. Ce devis est valid√© par le propri√©taire. Le jour de l‚Äôaccident, l‚Äô√©quipe intervient pour cette prestation approuv√©e. Le plombier chauffagiste r√©alise seul l'entretien de la chaudi√®re dans le local d√©di√© et ses deux coll√®gues r√©alisent le d√©sembouage des radiateurs dans l‚Äôhabitation. Pour r√©aliser le test de combustion, le plombier chauffagiste allume la chaudi√®re. Il met la sonde de l'analyseur de combustion au niveau de l'√©vacuation des fum√©es. Suivant le br√ªleur et les valeurs fournies par l'analyseur, il r√®gle la chaudi√®re. Il est accroupi √† proximit√© de la chaudi√®re. La chaudi√®re explose, le local de la chaudi√®re est envahi de fum√©e et de vapeurs d'eau. A la suite de l‚Äôexplosion, le br√ªleur de la chaudi√®re est au sol devant la chaudi√®re. Il a √©t√© √©ject√©. La trappe d'acc√®s de la chambre de combustion, au-dessus du br√ªleur, est cass√©e sur un angle. A l'int√©rieur de la chambre de combustion, dans le fond, la cuve en fonte pr√©sente un trou. Le plombier chauffagiste se dirige vers la sortie, puis vers le v√©hicule de l'entreprise. Il se regarde dans le r√©troviseur du v√©hicule car son visage le br√ªle. Il constate qu'il n'est pas br√ªl√© sur le visage. Il se d√©shabille lui-m√™me. Son coll√®gue appelle les pompiers. A leur arriv√©e, le plombier est dans la baignoire de l'habitation √† une eau temp√©r√©e, toujours conscient. Il est br√ªl√© par de la vapeur d‚Äôeau sur plus de 50 % du corps aux niveaux des bras, du torse, des parties intimes et des jambes. Hypoth√®ses pour expliquer l‚Äôexplosion de la chaudi√®re : sur le d√©part du r√©seau d'eau de chauffage de la chaudi√®re, il y a des dispositifs de s√©curit√© : un vase d'expansion suivi d'une soupape de s√©curit√©. Le vase d'expansion compense le surplus de volume d'eau quand elle chauffe, il se d√©clenche quand la temp√©rature atteint 60¬∞C. La soupape de s√©curit√© se d√©clenche si la pression atteint les 3 bars. La vanne purge l'eau du circuit pour qu'elle s'√©coule dans le local de la chaudi√®re, hors du r√©seau d'eau de chauffage. Le jour de l'accident, la vanne d‚Äôisolement (entre la chaudi√®re et le r√©seau d‚Äôeau de l‚Äôhabitation pour le chauffage) est ferm√©e. Ce qui permet au plombier chauffagiste de r√©aliser le contr√¥le de combustion sur la chaudi√®re et √† ses coll√®gues de continuer le d√©sembouage sur les radiateurs. Cette vanne est situ√©e avant les dispositifs de s√©curit√© de la chaudi√®re. De ce fait, lorsque le plombier chauffagiste a allum√© la chaudi√®re, la temp√©rature de l'eau augmente ce qui engendre une √©l√©vation de la pression. Les dispositifs de s√©curit√© √©tant situ√©s apr√®s la vanne d'isolement, ils ne se d√©clenchent pas lorsque la temp√©rature et la pression atteignent les valeurs de d√©clenchement. La chaudi√®re continue de chauffer l‚Äôeau jusqu‚Äô√† ce qu‚Äôelle se transforme en vapeur. La pression dans le circuit de la chaudi√®re est telle que la chaudi√®re explose avec la lib√©ration de la vapeur d'eau dans le local.\"\n",
    "}\n",
    "\n",
    "len(epicea_example[\"R√©sum√© de l'accident\"].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b08ccd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, Any\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1409eb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cache HIT for context hash: e07b551b\n",
      "response=1\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import Field\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\",\n",
    "    stream_usage=True,\n",
    "    reasoning_effort=\"low\",\n",
    "    service_tier=\"flex\"\n",
    ")\n",
    "\n",
    "SYSTEM_MESSAGE = SystemMessage(content=\"Tu es un assistant fran√ßais. R√©ponds UNIQUEMENT en fran√ßais avec des r√©ponses courtes et pr√©cises. Ne jamais utiliser l'anglais.\" \\\n",
    "            \"Tu es un expert en extraction de donn√©es. Il va t'etre pass√© du text non structur√©, et tu dois le convertir dans la structure donn√©e. \" \\\n",
    "            \"Si un nombre n'est pas mentionn√©, r√©pond 0\")\n",
    "\n",
    "class NumberSchema(BaseModel):\n",
    "    response:int\n",
    "\n",
    "class TextSchema(BaseModel):\n",
    "    response:str\n",
    "\n",
    "class Substance(BaseModel):\n",
    "    \"\"\"Single chemical substance involved in incident.\"\"\"\n",
    "    name: str = Field(..., description=\"Chemical name\")\n",
    "    cas_number: str = Field(..., description=\"CAS registry number\")\n",
    "    quantity: str = Field(..., description=\"Quantity released/spilled\")\n",
    "    clp_class: str = Field(..., description=\"CLP hazard classification\")\n",
    "\n",
    "class SubstancesOutput(BaseModel):\n",
    "    \"\"\"Extracted substances from accident report (0 to many).\"\"\"\n",
    "    response: List[Substance] = Field(default_factory=list, description=\"List of substances\")\n",
    "\n",
    "class DiskCache:\n",
    "    def __init__(self, cache_file: str = \"cache.json\"):\n",
    "        self.cache_file = cache_file\n",
    "        try:\n",
    "            with open(cache_file, 'r') as f:\n",
    "                self.cache: Dict[str, Dict[str, Any]] = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            self.cache = {}\n",
    "    \n",
    "    def get(self, context_hash: str, schema):\n",
    "        if context_hash in self.cache:\n",
    "            data = self.cache[context_hash]\n",
    "            return schema(**data)\n",
    "        return None\n",
    "    \n",
    "    def set(self, context_hash: str, result):\n",
    "        self.cache[context_hash] = result.model_dump()\n",
    "        with open(self.cache_file, 'w') as f:\n",
    "            json.dump(self.cache, f)\n",
    "    \n",
    "    def extract(self, context: str, schema, force_run : bool = False):\n",
    "        context_hash = hashlib.md5(context.encode()).hexdigest()\n",
    "        \n",
    "        if not force_run :\n",
    "            cached = self.get(context_hash, schema)\n",
    "            if cached:\n",
    "                print(f\"‚úÖ Cache HIT for context hash: {context_hash[:8]}\")\n",
    "                return cached\n",
    "        \n",
    "        print(f\"üîÑ Cache MISS - calling API for hash: {context_hash[:8]}\")\n",
    "        \n",
    "        messages = [\n",
    "            SYSTEM_MESSAGE,\n",
    "            HumanMessage(content=context)\n",
    "        ]\n",
    "\n",
    "        structured_llm = llm.with_structured_output(schema, include_raw=True)\n",
    "        result = structured_llm.invoke(messages)\n",
    "        \n",
    "        self.set(context_hash, result[\"parsed\"])\n",
    "        return result[\"parsed\"]\n",
    "\n",
    "context = epicea_example[\"R√©sum√© de l'accident\"]\n",
    "cache = DiskCache()\n",
    "result = cache.extract(f\"Extrait le nombre d'accident√©s de ceci:\\n\\n{context}\", NumberSchema)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c3c8a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai(field: str, context: str) -> List[Substance] | str:   \n",
    "    prompts = {\n",
    "        \"title\" : {\"prompt\":f\"J'ai besoin d'un titre qui r√©sume en une petite phrase cette description:\\n{context}\", \"schema\": TextSchema},\n",
    "        \"fatalities\" : {\"prompt\":f\"Combien de morts y a t il dans la description suivante:\\n{context}\\n\\n\\nNe r√©pond qu'un seul nombre\", \"schema\": NumberSchema},\n",
    "        \"injuries\" : {\"prompt\":f\"Combien de bless√©s y a t il dans la description suivante:\\n{context}\\n\\n\\nNe r√©pond qu'un seul nombre\", \"schema\": NumberSchema},\n",
    "        \"evacuated\" : {\"prompt\":f\"Combien de personnes √©vacu√©es y a t il dans la description suivante:\\n{context}\\n\\n\\nNe r√©pond qu'un seul nombre\", \"schema\": NumberSchema},\n",
    "        \"hospitalized\" : {\"prompt\":f\"Combien de personnes hospitalis√©es y a t il dans la description suivante:\\n{context}\\n\\n\\nNe r√©pond qu'un seul nombre\", \"schema\": NumberSchema},\n",
    "        \"substances\" : {\"prompt\":f\"Quelles substances sont en jeu dans la description suivante:\\n{context}\\n\\n\\nS'il n'y en a pas r√©pond un JSON vide. Si la quantit√© n'est pas renseign√©e, ne met rien\", \"schema\":SubstancesOutput},\n",
    "    }\n",
    "\n",
    "    if field not in prompts.keys():\n",
    "        return \"<AI> To Prompt\"\n",
    "\n",
    "    selectedPrompt = prompts[field][\"prompt\"]\n",
    "    selectedSchema = prompts[field][\"schema\"]\n",
    "    response = cache.extract(selectedPrompt, selectedSchema).response\n",
    "    \n",
    "    print(field, response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2deb5396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 996.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cache HIT for context hash: 15245758\n",
      "title Explosion d'une chaudi√®re fioul lors d'un test de combustion pendant un entretien, entra√Ænant des br√ªlures graves et des dommages au local\n",
      "‚úÖ Cache HIT for context hash: 3ff0a5ab\n",
      "substances [Substance(name='Fioul domestique', cas_number='', quantity='', clp_class=''), Substance(name='Eau', cas_number='', quantity='', clp_class=''), Substance(name=\"Vapeur d'eau\", cas_number='', quantity='', clp_class='')]\n",
      "============================ [Substance(name='Fioul domestique', cas_number='', quantity='', clp_class=''), Substance(name='Eau', cas_number='', quantity='', clp_class=''), Substance(name=\"Vapeur d'eau\", cas_number='', quantity='', clp_class='')]\n",
      "‚úÖ Cache HIT for context hash: 83be0a1b\n",
      "fatalities 0\n",
      "‚úÖ Cache HIT for context hash: d6bdc15b\n",
      "injuries 1\n",
      "‚úÖ Cache HIT for context hash: b466a542\n",
      "evacuated 0\n",
      "‚úÖ Cache HIT for context hash: c793bf1b\n",
      "hospitalized 1\n",
      "<class 'list'>\n",
      "0 ========================================================================================================================================================================================================\n",
      "sites"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "address": "NULL",
       "country": "France",
       "industrial_activity": "B√¢timent et Travaux Publics",
       "latitude": null,
       "longitude": null,
       "plant_name": "",
       "site_id": "a7f85737-bcdb-5c5b-a60d-64ce1643bb98"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accidents"
     ]
    },
    {
     "data": {
      "application/json": {
       "accident_date": "NULL",
       "accident_id": "f8f8d370-319a-5910-b92b-540f206d50a2",
       "created_at": "date.now()",
       "raw_data": "",
       "severity_scale": "NULL",
       "site_id": "a7f85737-bcdb-5c5b-a60d-64ce1643bb98",
       "source": "EPICEA",
       "source_id": "27615",
       "title": "Explosion d'une chaudi√®re fioul lors d'un test de combustion pendant un entretien, entra√Ænant des br√ªlures graves et des dommages au local",
       "updated_at": ""
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "causes"
     ]
    },
    {
     "data": {
      "application/json": {
       "accident_id": "f8f8d370-319a-5910-b92b-540f206d50a2",
       "description": "Une √©quipe de trois salari√©s dont un plombier chauffagiste, √¢g√© de 30 ans, intervient chez un particulier, un v√©t√©rinaire dont l'habitation se compose d'une maison et d'un bloc op√©ratoire (achet√©e il y a 21 ans auparavant, maison construite dans les ann√©es 70). L'installation de chauffage de l'habitation, compos√©e d‚Äôune pompe √† chaleur et d‚Äôune chaudi√®re au fioul, alimente les 28 radiateurs de la propri√©t√©. L'alimentation en eau chaude est assur√©e par un ballon d'eau ind√©pendant de l'installation de chauffage. Une chaudi√®re au fioul de la marque *** est plac√©e dans un local √† proximit√© de l'habitation. La chaudi√®re fonctionne en relai de la pompe √† chaleur. Quand la pompe n'arrive plus √† maintenir la consigne de temp√©rature, la chaudi√®re au fioul fonctionne (le propri√©taire de l‚Äôinstallation ne dispose pas du manuel d'utilisation ou d'installation de la chaudi√®re). Le propri√©taire rencontre des difficult√©s sur le fonctionnement de la chaudi√®re au fioul mais ne valide pas le premier devis pour la remplacer. Le second devis propose une remise en √©tat de la chaudi√®re existante avec un d√©sembouage des radiateurs, le remplacement des vannes des radiateurs, l'alimentation entre la cuve de fioul et la chaudi√®re et le ramonage. Ce devis est valid√© par le propri√©taire. Le jour de l‚Äôaccident, l‚Äô√©quipe intervient pour cette prestation approuv√©e. Le plombier chauffagiste r√©alise seul l'entretien de la chaudi√®re dans le local d√©di√© et ses deux coll√®gues r√©alisent le d√©sembouage des radiateurs dans l‚Äôhabitation. Pour r√©aliser le test de combustion, le plombier chauffagiste allume la chaudi√®re. Il met la sonde de l'analyseur de combustion au niveau de l'√©vacuation des fum√©es. Suivant le br√ªleur et les valeurs fournies par l'analyseur, il r√®gle la chaudi√®re. Il est accroupi √† proximit√© de la chaudi√®re. La chaudi√®re explose, le local de la chaudi√®re est envahi de fum√©e et de vapeurs d'eau. A la suite de l‚Äôexplosion, le br√ªleur de la chaudi√®re est au sol devant la chaudi√®re. Il a √©t√© √©ject√©. La trappe d'acc√®s de la chambre de combustion, au-dessus du br√ªleur, est cass√©e sur un angle. A l'int√©rieur de la chambre de combustion, dans le fond, la cuve en fonte pr√©sente un trou. Le plombier chauffagiste se dirige vers la sortie, puis vers le v√©hicule de l'entreprise. Il se regarde dans le r√©troviseur du v√©hicule car son visage le br√ªle. Il constate qu'il n'est pas br√ªl√© sur le visage. Il se d√©shabille lui-m√™me. Son coll√®gue appelle les pompiers. A leur arriv√©e, le plombier est dans la baignoire de l'habitation √† une eau temp√©r√©e, toujours conscient. Il est br√ªl√© par de la vapeur d‚Äôeau sur plus de 50 % du corps aux niveaux des bras, du torse, des parties intimes et des jambes. Hypoth√®ses pour expliquer l‚Äôexplosion de la chaudi√®re : sur le d√©part du r√©seau d'eau de chauffage de la chaudi√®re, il y a des dispositifs de s√©curit√© : un vase d'expansion suivi d'une soupape de s√©curit√©. Le vase d'expansion compense le surplus de volume d'eau quand elle chauffe, il se d√©clenche quand la temp√©rature atteint 60¬∞C. La soupape de s√©curit√© se d√©clenche si la pression atteint les 3 bars. La vanne purge l'eau du circuit pour qu'elle s'√©coule dans le local de la chaudi√®re, hors du r√©seau d'eau de chauffage. Le jour de l'accident, la vanne d‚Äôisolement (entre la chaudi√®re et le r√©seau d‚Äôeau de l‚Äôhabitation pour le chauffage) est ferm√©e. Ce qui permet au plombier chauffagiste de r√©aliser le contr√¥le de combustion sur la chaudi√®re et √† ses coll√®gues de continuer le d√©sembouage sur les radiateurs. Cette vanne est situ√©e avant les dispositifs de s√©curit√© de la chaudi√®re. De ce fait, lorsque le plombier chauffagiste a allum√© la chaudi√®re, la temp√©rature de l'eau augmente ce qui engendre une √©l√©vation de la pression. Les dispositifs de s√©curit√© √©tant situ√©s apr√®s la vanne d'isolement, ils ne se d√©clenchent pas lorsque la temp√©rature et la pression atteignent les valeurs de d√©clenchement. La chaudi√®re continue de chauffer l‚Äôeau jusqu‚Äô√† ce qu‚Äôelle se transforme en vapeur. La pression dans le circuit de la chaudi√®re est telle que la chaudi√®re explose avec la lib√©ration de la vapeur d'eau dans le local.",
       "equipment_failure": "270302 - Chaudi√®re √† mazout",
       "event_category": "Travaux d'installation √©lectrique dans tous locaux"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substances"
     ]
    },
    {
     "data": {
      "application/json": {
       "substances": [
        {
         "cas_number": "",
         "clp_class": "",
         "name": "Fioul domestique",
         "quantity": ""
        },
        {
         "cas_number": "",
         "clp_class": "",
         "name": "Eau",
         "quantity": ""
        },
        {
         "cas_number": "",
         "clp_class": "",
         "name": "Vapeur d'eau",
         "quantity": ""
        }
       ]
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consequences_human"
     ]
    },
    {
     "data": {
      "application/json": {
       "accident_id": "f8f8d370-319a-5910-b92b-540f206d50a2",
       "evacuated": 0,
       "fatalities": 0,
       "hospitalized": 1,
       "injuries": 1
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consequences_other"
     ]
    },
    {
     "data": {
      "application/json": {
       "accident_id": "f8f8d370-319a-5910-b92b-540f206d50a2",
       "disruption_duration": "<AI> To Prompt",
       "economic_cost": "<AI> To Prompt",
       "environmental_impact": "<AI> To Prompt"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_to_db(df : pd.DataFrame, trunc = None):    \n",
    "\n",
    "    if trunc is not None :\n",
    "        df = df.head(trunc)\n",
    "\n",
    "    def create_line(line : pd.Series):\n",
    "        address = \"NULL\"\n",
    "        site_id = str(uuid5(UUID_NAMESPACE, address))\n",
    "        sites = {\n",
    "            \"site_id\" : site_id,\n",
    "            \"plant_name\": \"\",\n",
    "            \"address\": address,\n",
    "            \"latitude\": None,\n",
    "            \"longitude\": None,\n",
    "            \"country\": \"France\",\n",
    "            \"industrial_activity\": line[\"Comit√© technique national\"].split(' - ')[1],\n",
    "        }\n",
    "\n",
    "        CONTEXT_FOR_AI = line[\"R√©sum√© de l'accident\"]\n",
    "        title : str = ask_ai(\"title\", CONTEXT_FOR_AI) # type: ignore\n",
    "\n",
    "        accident_key = \" \".join([title, str(line[\"Num√©ro du dossier\"])])\n",
    "        accident_id = str(uuid5(UUID_NAMESPACE, accident_key))\n",
    "        accidents = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"site_id\": site_id,\n",
    "            \"title\": title,\n",
    "            \"source\": \"EPICEA\",\n",
    "            \"source_id\": str(line[\"Num√©ro du dossier\"]),\n",
    "            \"accident_date\": \"NULL\",\n",
    "            \"severity_scale\": \"NULL\",\n",
    "            \"raw_data\": \"\", #line,\n",
    "            \"created_at\": \"date.now()\",\n",
    "            \"updated_at\": \"\",\n",
    "        }\n",
    "\n",
    "        causes = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"event_category\": line[\"Code entreprise\"].split(' - ')[1],\n",
    "            \"equipment_failure\": line[\"Mat√©riel en cause\"],\n",
    "            \"description\": line[\"R√©sum√© de l'accident\"], \n",
    "        }\n",
    "\n",
    "        substancesOutput : List[Substance] = ask_ai(\"substances\", CONTEXT_FOR_AI) # type: ignore\n",
    "        print(\"============================\", substancesOutput)\n",
    "        substancesArray = []\n",
    "        for substance in substancesOutput :\n",
    "            substanceJSON = {\n",
    "                \"name\":substance.name,\n",
    "                \"cas_number\":substance.cas_number,\n",
    "                \"quantity\":substance.quantity,\n",
    "                \"clp_class\":substance.clp_class\n",
    "            }\n",
    "            substancesArray.append(substanceJSON)\n",
    "        substances = {\"substances\":substancesArray}\n",
    "\n",
    "        consequences_human = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"fatalities\": ask_ai(\"fatalities\", CONTEXT_FOR_AI),\n",
    "            \"injuries\": ask_ai(\"injuries\", CONTEXT_FOR_AI),\n",
    "            \"evacuated\": ask_ai(\"evacuated\", CONTEXT_FOR_AI),\n",
    "            \"hospitalized\": ask_ai(\"hospitalized\", CONTEXT_FOR_AI),\n",
    "        }\n",
    "\n",
    "        consequences_other = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"environmental_impact\": ask_ai(\"environmental_impact\", CONTEXT_FOR_AI),\n",
    "            \"economic_cost\": ask_ai(\"economic_cost\", CONTEXT_FOR_AI),\n",
    "            \"disruption_duration\": ask_ai(\"disruption_duration\", CONTEXT_FOR_AI)\n",
    "        }\n",
    "\n",
    "        tables = {\n",
    "            \"sites\": sites,\n",
    "            \"accidents\": accidents,\n",
    "            \"causes\": causes,\n",
    "            \"substances\": substances,\n",
    "            \"consequences_human\": consequences_human,\n",
    "            \"consequences_other\": consequences_other\n",
    "        }\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    db_lines = []\n",
    "\n",
    "    for x in tqdm(iter(df.iloc), total=trunc, ncols=200):\n",
    "        db_lines.append(create_line(x))\n",
    "\n",
    "    return db_lines\n",
    "\n",
    "df = pd.DataFrame(epicea_example, index=[0])\n",
    "EPICEA_db_jsons = convert_to_db(df)\n",
    "print(type(EPICEA_db_jsons))\n",
    "print_db_jsons(EPICEA_db_jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e77b41",
   "metadata": {},
   "source": [
    "# Database Inserting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b0d644c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting sites\n"
     ]
    },
    {
     "ename": "UndefinedTable",
     "evalue": "relation \"sites\" does not exist\nLINE 1: INSERT INTO sites (site_id, plant_name, address, latitude, l...\n                    ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m conn_string \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEON_CONNECTION_STRING\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m psycopg2\u001b[38;5;241m.\u001b[39mconnect(conn_string) \u001b[38;5;28;01mas\u001b[39;00m conn : \n\u001b[1;32m--> 112\u001b[0m     \u001b[43minsert_jsons_in_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mARIA_db_jsons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[98], line 26\u001b[0m, in \u001b[0;36minsert_jsons_in_db\u001b[1;34m(db_jsons, conn)\u001b[0m\n\u001b[0;32m     15\u001b[0m     sites_tuples\u001b[38;5;241m.\u001b[39mappend((\n\u001b[0;32m     16\u001b[0m         db_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msites\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msite_id\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     17\u001b[0m         db_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msites\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplant_name\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m         db_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msites\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindustrial_activity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     23\u001b[0m     ))\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserting sites\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mexecute_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mINSERT INTO sites (site_id, plant_name, address, latitude, longitude, country, industrial_activity) VALUES \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m ON CONFLICT (plant_name, address) DO NOTHING\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msites_tuples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m cur\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124m    SELECT site_id, plant_name, address \u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124m    FROM sites\u001b[39m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m all_sites \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mfetchall()\n",
      "File \u001b[1;32mn:\\WiseTwin\\.venv\\lib\\site-packages\\psycopg2\\extras.py:1299\u001b[0m, in \u001b[0;36mexecute_values\u001b[1;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1298\u001b[0m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m post\n\u001b[1;32m-> 1299\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch:\n\u001b[0;32m   1301\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(cur\u001b[38;5;241m.\u001b[39mfetchall())\n",
      "\u001b[1;31mUndefinedTable\u001b[0m: relation \"sites\" does not exist\nLINE 1: INSERT INTO sites (site_id, plant_name, address, latitude, l...\n                    ^\n"
     ]
    }
   ],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def insert_jsons_in_db(db_jsons, conn):\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # 1. Insert sites\n",
    "    # Generate an array of tuples without duplicates\n",
    "    constraint_set = set()\n",
    "    sites_tuples = []\n",
    "    for db_json in db_jsons:\n",
    "        constraint_key = db_json[\"sites\"][\"plant_name\"] + db_json[\"sites\"][\"address\"]\n",
    "        if constraint_key in constraint_set : continue\n",
    "        constraint_set.add(constraint_key)\n",
    "\n",
    "        sites_tuples.append((\n",
    "            db_json[\"sites\"][\"site_id\"],\n",
    "            db_json[\"sites\"][\"plant_name\"], \n",
    "            db_json[\"sites\"][\"address\"], \n",
    "            db_json[\"sites\"][\"latitude\"], \n",
    "            db_json[\"sites\"][\"longitude\"], \n",
    "            db_json[\"sites\"][\"country\"], \n",
    "            db_json[\"sites\"][\"industrial_activity\"]\n",
    "        ))\n",
    "\n",
    "    print(\"Inserting sites\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO sites (site_id, plant_name, address, latitude, longitude, country, industrial_activity) VALUES %s ON CONFLICT (plant_name, address) DO NOTHING\"\"\", sites_tuples)\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT site_id, plant_name, address \n",
    "        FROM sites\n",
    "    \"\"\")\n",
    "    all_sites = cur.fetchall()\n",
    "    site_mapping = {(row[1], row[2]): row[0] for row in all_sites}\n",
    "\n",
    "    # Insert accidents  \n",
    "    accidents_tuples = [\n",
    "        (\n",
    "            db_json[\"accidents\"][\"accident_id\"], \n",
    "            site_mapping[(db_json[\"sites\"][\"plant_name\"], db_json[\"sites\"][\"address\"])], \n",
    "            db_json[\"accidents\"][\"title\"], \n",
    "            db_json[\"accidents\"][\"source\"], \n",
    "            db_json[\"accidents\"][\"source_id\"], \n",
    "            db_json[\"accidents\"][\"accident_date\"], \n",
    "            db_json[\"accidents\"][\"severity_scale\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting accidents\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO accidents (accident_id, site_id, title, source, source_id, accident_date, severity_scale) VALUES %s ON CONFLICT DO NOTHING\"\"\", accidents_tuples)\n",
    "\n",
    "    # Insert causes\n",
    "    causes_tuples = [\n",
    "        (\n",
    "            db_json[\"causes\"][\"accident_id\"], \n",
    "            db_json[\"causes\"][\"event_category\"], \n",
    "            db_json[\"causes\"][\"equipment_failure\"], \n",
    "            db_json[\"causes\"][\"description\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting causes\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO causes (accident_id, event_category, equipment_failure, description) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", causes_tuples)\n",
    "\n",
    "    # Insert substances\n",
    "    substances_tuples = [\n",
    "        (\n",
    "            db_json[\"substances\"][\"accident_id\"], \n",
    "            db_json[\"substances\"][\"name\"], \n",
    "            db_json[\"substances\"][\"cas_number\"], \n",
    "            db_json[\"substances\"][\"quantity\"], \n",
    "            db_json[\"substances\"][\"clp_class\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting substances\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO substances (accident_id, name, cas_number, quantity, clp_class) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", substances_tuples)\n",
    "\n",
    "    # Insert human consequences\n",
    "    human_tuples = [\n",
    "        (\n",
    "            db_json[\"consequences_human\"][\"accident_id\"], \n",
    "            db_json[\"consequences_human\"][\"fatalities\"], \n",
    "            db_json[\"consequences_human\"][\"injuries\"], \n",
    "            db_json[\"consequences_human\"][\"evacuated\"], \n",
    "            db_json[\"consequences_human\"][\"hospitalized\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting consequences_human\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO consequences_human (accident_id, fatalities, injuries, evacuated, hospitalized) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", human_tuples)\n",
    "\n",
    "    # Insert other consequences\n",
    "    other_tuples = [\n",
    "        (\n",
    "            db_json[\"consequences_other\"][\"accident_id\"], \n",
    "            db_json[\"consequences_other\"][\"environmental_impact\"], \n",
    "            db_json[\"consequences_other\"][\"economic_cost\"], \n",
    "            db_json[\"consequences_other\"][\"disruption_duration\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting consequences_other\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO consequences_other (accident_id, environmental_impact, economic_cost, disruption_duration) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", other_tuples)\n",
    "\n",
    "    # Commit all inserts\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "\n",
    "conn_string = os.getenv(\"NEON_CONNECTION_STRING\")\n",
    "\n",
    "with psycopg2.connect(conn_string) as conn : \n",
    "    insert_jsons_in_db(ARIA_db_jsons, conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

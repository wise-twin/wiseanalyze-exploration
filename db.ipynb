{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install tqdm\n",
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid5, UUID\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID_NAMESPACE = UUID(\"c87c53d6-4464-4018-b4c9-15718d354ec8\")\n",
    "UUID_NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04ec38",
   "metadata": {},
   "source": [
    "# ARIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbe1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./accidents-tous-req10905.csv\", encoding=\"cp1252\", sep=\";\", skiprows=7)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44642c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(df : pd.DataFrame, trunc = None):    \n",
    "\n",
    "    if trunc is not None :\n",
    "        df = df.head(trunc)\n",
    "\n",
    "    def create_line(line : pd.Series):\n",
    "        address = \" \".join([str(line[\"Départment\"]), str(line[\"Commune\"])])\n",
    "        site_id = str(uuid5(UUID_NAMESPACE, address))\n",
    "        sites = {\n",
    "            \"site_id\" : site_id,\n",
    "            \"plant_name\": \"\",\n",
    "            \"address\": address,\n",
    "            \"latitude\": None,               # to fill later\n",
    "            \"longitude\": None,              # to fill later\n",
    "            \"country\": line[\"Pays\"],\n",
    "            \"industrial_activity\": line[\"Code NAF\"],\n",
    "        }\n",
    "\n",
    "        accident_key = \" \".join([str(line[\"Titre\"]), str(line[\"Date\"])])\n",
    "        accident_id = str(uuid5(UUID_NAMESPACE, accident_key))\n",
    "        accidents = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"site_id\": site_id,\n",
    "            \"title\": line[\"Titre\"],\n",
    "            \"source\": \"ARIA\",\n",
    "            \"source_id\": str(line[\"Numéro ARIA\"]),\n",
    "            \"accident_date\": line[\"Date\"],\n",
    "            \"severity_scale\": line[\"Echelle\"],\n",
    "            \"raw_data\": \"\", #line,\n",
    "            \"created_at\": \"date.now()\",\n",
    "            \"updated_at\": \"\",\n",
    "        }\n",
    "\n",
    "        causes = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"event_category\": line[\"Causes profondes\"],\n",
    "            \"equipment_failure\": line[\"Causes premières\"],\n",
    "            \"description\": line[\"Contenu\"], # could also reuse Contenu\n",
    "        }\n",
    "\n",
    "        substances = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"name\": line[\"Matières\"],\n",
    "            \"cas_number\": \"\",\n",
    "            \"quantity\": \"\",\n",
    "            \"clp_class\" : line[\"Classe de danger CLP\"]\n",
    "        }\n",
    "\n",
    "        consequences_human = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"fatalities\": None,\n",
    "            \"injuries\": None,\n",
    "            \"evacuated\": None,\n",
    "            \"hospitalized\": None,\n",
    "        }\n",
    "\n",
    "        consequences = {\n",
    "            \"ENVIRONNEMENTALES\" : \"\",\n",
    "            \"ÉCONOMIQUES\" : \"\"\n",
    "        }\n",
    "\n",
    "        try :\n",
    "            for consequence in line[\"Conséquences\"].split(\"CONSÉQUENCES \"):\n",
    "                if len(consequence) < 2 : continue\n",
    "                s = consequence.split(',')\n",
    "                key = s[0]\n",
    "                content = (','.join(s[1:])).removesuffix(',')\n",
    "                consequences[key] = content\n",
    "        except : pass\n",
    "\n",
    "        consequences_other = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"environmental_impact\": consequences[\"ENVIRONNEMENTALES\"],\n",
    "            \"economic_cost\": consequences[\"ÉCONOMIQUES\"],\n",
    "            \"disruption_duration\": line[\"Type évènement\"]\n",
    "        }\n",
    "\n",
    "        tables = {\n",
    "            \"sites\": sites,\n",
    "            \"accidents\": accidents,\n",
    "            \"causes\": causes,\n",
    "            \"substances\": substances,\n",
    "            \"consequences_human\": consequences_human,\n",
    "            \"consequences_other\": consequences_other\n",
    "        }\n",
    "\n",
    "        # taken_cols = [\"Titre\", \"Pays\", \"Code NAF\", \"Numéro ARIA\", \"Date\", \"Echelle\", \"Causes profondes\", \"Causes premières\", \"Contenu\", \"Matières\", \"Conséquences\", \"Départment\", \"Commune\", \"Classe de danger CLP\", \"Type évènement\"]\n",
    "        # print(line.drop(labels=taken_cols, errors='ignore'))\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    db_lines = []\n",
    "\n",
    "    for x in tqdm(iter(df.iloc), total=trunc, ncols=200):\n",
    "        db_lines.append(create_line(x))\n",
    "\n",
    "    return db_lines\n",
    "\n",
    "ARIA_db_jsons = convert_to_db(df, trunc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON, display\n",
    "\n",
    "def print_db_jsons(json):\n",
    "    for i, db_line in enumerate(json):\n",
    "        print(i, \"=\" * 200)\n",
    "        for key in db_line :\n",
    "            print(key, flush=True, end='')\n",
    "            display(JSON(db_line[key], expanded=True))\n",
    "        if i == 0 : break\n",
    "\n",
    "print_db_jsons(ARIA_db_jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0156a",
   "metadata": {},
   "source": [
    "# OSHA - Injuries (ITA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5110c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./OSHA ITA.csv\", sep=\",\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bac5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3dbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(df : pd.DataFrame, trunc = None):    \n",
    "\n",
    "    if trunc is not None :\n",
    "        df = df.head(trunc)\n",
    "\n",
    "    def create_line(line : pd.Series):\n",
    "        address = f\"{line['street_address']} {line['city']} {line['state']} {line['zip_code']}\"\n",
    "        site_key = line[\"establishment_name\"] + \" \" + address\n",
    "        site_id = str(uuid5(UUID_NAMESPACE, site_key))\n",
    "        sites = {\n",
    "            \"site_id\" : site_id,\n",
    "            \"plant_name\": line[\"establishment_name\"],  # or fallback to \"company_name\"\n",
    "            \"address\": address,\n",
    "            \"latitude\": None,  # Geocode later from address\n",
    "            \"longitude\": None,\n",
    "            \"country\": \"USA\",\n",
    "            \"industrial_activity\": str(line[\"naics_code\"]),  # Maps to NAF equivalent\n",
    "        }\n",
    "\n",
    "        accident_key = \" \".join([line[\"job_description\"], line[\"date_of_incident\"]])\n",
    "        accident_id = str(uuid5(UUID_NAMESPACE, accident_key))\n",
    "        accidents = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"site_id\": site_id,\n",
    "            \"title\": line[\"job_description\"],  # Brief incident summary\n",
    "            \"source\": \"OSHA ITA\",\n",
    "            \"source_id\": line[\"case_number\"],  # Unique OSHA case identifier\n",
    "            \"accident_date\": line[\"date_of_incident\"],\n",
    "            \"severity_scale\": int(line[\"incident_outcome\"]),  # 1 = Death / 2 = Days away from work / 3 = Job transfer or restriction / 4 = Other recordable case\n",
    "            \"raw_data\": \"\",# line.to_dict(),  # Full line as JSON\n",
    "            \"created_at\": \"date.now()\",\n",
    "            \"updated_at\": \"\",  # Fill on save\n",
    "        }\n",
    "\n",
    "        causes = {\n",
    "            \"accident_id\": accident_id, \n",
    "            \"event_category\": line[\"NEW_NAR_WHAT_HAPPENED\"],  # Deep/root causes\n",
    "            \"equipment_failure\": line[\"NEW_NAR_BEFORE_INCIDENT\"],  # Initial triggers\n",
    "            \"description\": line[\"NEW_INCIDENT_DESCRIPTION\"],\n",
    "        }\n",
    "\n",
    "        substances = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"name\": line[\"NEW_NAR_OBJECT_SUBSTANCE\"],  # Object/substance hit/contacted\n",
    "            \"cas_number\": \"\",  # Not in ITA; research via name if needed\n",
    "            \"quantity\": \"\",  # Derive from context if available\n",
    "            \"clp_class\": line[\"NEW_NAR_INJURY_ILLNESS\"],  # Injury type as hazard proxy\n",
    "        }\n",
    "\n",
    "        consequences_human = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"fatalities\": 1 if pd.notna(line[\"date_of_death\"]) else 0,\n",
    "            \"injuries\": 1,  # Each line is one recordable case\n",
    "            \"evacuated\": None,  # Not directly available\n",
    "            \"hospitalized\": 1 if line[\"dafw_num_away\"] > 0 else 0,  # Days away implies severity\n",
    "        }\n",
    "\n",
    "        consequences_other = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"environmental_impact\": \"\",  # ITA focuses on worker injuries\n",
    "            \"economic_cost\": \"\",  # Estimate from total_hours_worked if needed\n",
    "            \"disruption_duration\": int(line[\"djtr_num_tr\"]),  # Restriction days as proxy\n",
    "        }\n",
    "\n",
    "        tables = {\n",
    "            \"sites\": sites,\n",
    "            \"accidents\": accidents,\n",
    "            \"causes\": causes,\n",
    "            \"substances\": substances,\n",
    "            \"consequences_human\": consequences_human,\n",
    "            \"consequences_other\": consequences_other\n",
    "        }\n",
    "\n",
    "        # taken_cols = [\"Titre\", \"Pays\", \"Code NAF\", \"Numéro ARIA\", \"Date\", \"Echelle\", \"Causes profondes\", \"Causes premières\", \"Contenu\", \"Matières\", \"Conséquences\", \"Départment\", \"Commune\", \"Classe de danger CLP\", \"Type évènement\"]\n",
    "        # print(line.drop(labels=taken_cols, errors='ignore'))\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    db_lines = []\n",
    "\n",
    "    if trunc is None:\n",
    "        itr = iter(df.iloc)\n",
    "    else :\n",
    "        itr = iter(df.head(trunc).iloc)\n",
    "\n",
    "    for x in tqdm(itr, total=5, ncols=200):\n",
    "        db_lines.append(create_line(x))\n",
    "\n",
    "    return db_lines\n",
    "\n",
    "OSHA_db_jsons = convert_to_db(df, trunc=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_db_jsons(OSHA_db_jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e77b41",
   "metadata": {},
   "source": [
    "# Database Inserting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d644c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def insert_jsons_in_db(db_jsons, conn):\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # 1. Insert sites\n",
    "    # Generate an array of tuples without duplicates\n",
    "    constraint_set = set()\n",
    "    sites_tuples = []\n",
    "    for db_json in db_jsons:\n",
    "        constraint_key = db_json[\"sites\"][\"plant_name\"] + db_json[\"sites\"][\"address\"]\n",
    "        if constraint_key in constraint_set : continue\n",
    "        constraint_set.add(constraint_key)\n",
    "\n",
    "        sites_tuples.append((\n",
    "            db_json[\"sites\"][\"site_id\"],\n",
    "            db_json[\"sites\"][\"plant_name\"], \n",
    "            db_json[\"sites\"][\"address\"], \n",
    "            db_json[\"sites\"][\"latitude\"], \n",
    "            db_json[\"sites\"][\"longitude\"], \n",
    "            db_json[\"sites\"][\"country\"], \n",
    "            db_json[\"sites\"][\"industrial_activity\"]\n",
    "        ))\n",
    "\n",
    "    print(\"Inserting sites\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO sites (site_id, plant_name, address, latitude, longitude, country, industrial_activity) VALUES %s ON CONFLICT (plant_name, address) DO NOTHING\"\"\", sites_tuples)\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT site_id, plant_name, address \n",
    "        FROM sites\n",
    "    \"\"\")\n",
    "    all_sites = cur.fetchall()\n",
    "    site_mapping = {(row[1], row[2]): row[0] for row in all_sites}\n",
    "\n",
    "    # Insert accidents  \n",
    "    accidents_tuples = [\n",
    "        (\n",
    "            db_json[\"accidents\"][\"accident_id\"], \n",
    "            site_mapping[(db_json[\"sites\"][\"plant_name\"], db_json[\"sites\"][\"address\"])], \n",
    "            db_json[\"accidents\"][\"title\"], \n",
    "            db_json[\"accidents\"][\"source\"], \n",
    "            db_json[\"accidents\"][\"source_id\"], \n",
    "            db_json[\"accidents\"][\"accident_date\"], \n",
    "            db_json[\"accidents\"][\"severity_scale\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting accidents\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO accidents (accident_id, site_id, title, source, source_id, accident_date, severity_scale) VALUES %s ON CONFLICT DO NOTHING\"\"\", accidents_tuples)\n",
    "\n",
    "    # Insert causes\n",
    "    causes_tuples = [\n",
    "        (\n",
    "            db_json[\"causes\"][\"accident_id\"], \n",
    "            db_json[\"causes\"][\"event_category\"], \n",
    "            db_json[\"causes\"][\"equipment_failure\"], \n",
    "            db_json[\"causes\"][\"description\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting causes\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO causes (accident_id, event_category, equipment_failure, description) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", causes_tuples)\n",
    "\n",
    "    # Insert substances\n",
    "    substances_tuples = [\n",
    "        (\n",
    "            db_json[\"substances\"][\"accident_id\"], \n",
    "            db_json[\"substances\"][\"name\"], \n",
    "            db_json[\"substances\"][\"cas_number\"], \n",
    "            db_json[\"substances\"][\"quantity\"], \n",
    "            db_json[\"substances\"][\"clp_class\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting substances\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO substances (accident_id, name, cas_number, quantity, clp_class) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", substances_tuples)\n",
    "\n",
    "    # Insert human consequences\n",
    "    human_tuples = [\n",
    "        (\n",
    "            db_json[\"consequences_human\"][\"accident_id\"], \n",
    "            db_json[\"consequences_human\"][\"fatalities\"], \n",
    "            db_json[\"consequences_human\"][\"injuries\"], \n",
    "            db_json[\"consequences_human\"][\"evacuated\"], \n",
    "            db_json[\"consequences_human\"][\"hospitalized\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting consequences_human\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO consequences_human (accident_id, fatalities, injuries, evacuated, hospitalized) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", human_tuples)\n",
    "\n",
    "    # Insert other consequences\n",
    "    other_tuples = [\n",
    "        (\n",
    "            db_json[\"consequences_other\"][\"accident_id\"], \n",
    "            db_json[\"consequences_other\"][\"environmental_impact\"], \n",
    "            db_json[\"consequences_other\"][\"economic_cost\"], \n",
    "            db_json[\"consequences_other\"][\"disruption_duration\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting consequences_other\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO consequences_other (accident_id, environmental_impact, economic_cost, disruption_duration) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", other_tuples)\n",
    "\n",
    "    # Commit all inserts\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "\n",
    "print(len(ARIA_db_jsons))\n",
    "\n",
    "with psycopg2.connect(host=\"localhost\", database=\"postgres\", user=\"postgres\", password=\"7833\", port=5432) as conn : \n",
    "    insert_jsons_in_db(ARIA_db_jsons, conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

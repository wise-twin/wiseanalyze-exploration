{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install tqdm\n",
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Sync errors\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'    # Detailed asserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid5, UUID\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec41606",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c7dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID_NAMESPACE = UUID(\"c87c53d6-4464-4018-b4c9-15718d354ec8\")\n",
    "UUID_NAMESPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04ec38",
   "metadata": {},
   "source": [
    "# ARIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bbe1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./accidents-tous-req10905.csv\", encoding=\"cp1252\", sep=\";\", skiprows=7)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44642c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(df : pd.DataFrame, trunc = None):    \n",
    "\n",
    "    if trunc is not None :\n",
    "        df = df.head(trunc)\n",
    "\n",
    "    def create_line(line : pd.Series):\n",
    "        address = \" \".join([str(line[\"D√©partment\"]), str(line[\"Commune\"])])\n",
    "        site_id = str(uuid5(UUID_NAMESPACE, address))\n",
    "        sites = {\n",
    "            \"site_id\" : site_id,\n",
    "            \"plant_name\": \"\",\n",
    "            \"address\": address,\n",
    "            \"latitude\": None,               # to fill later\n",
    "            \"longitude\": None,              # to fill later\n",
    "            \"country\": line[\"Pays\"],\n",
    "            \"industrial_activity\": line[\"Code NAF\"],\n",
    "        }\n",
    "\n",
    "        accident_key = \" \".join([str(line[\"Titre\"]), str(line[\"Date\"])])\n",
    "        accident_id = str(uuid5(UUID_NAMESPACE, accident_key))\n",
    "        accidents = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"site_id\": site_id,\n",
    "            \"title\": line[\"Titre\"],\n",
    "            \"source\": \"ARIA\",\n",
    "            \"source_id\": str(line[\"Num√©ro ARIA\"]),\n",
    "            \"accident_date\": line[\"Date\"],\n",
    "            \"severity_scale\": line[\"Echelle\"],\n",
    "            \"raw_data\": \"\", #line,\n",
    "            \"created_at\": \"date.now()\",\n",
    "            \"updated_at\": \"\",\n",
    "        }\n",
    "\n",
    "        causes = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"event_category\": line[\"Causes profondes\"],\n",
    "            \"failure\": line[\"Causes premi√®res\"],\n",
    "            \"description\": line[\"Contenu\"], # could also reuse Contenu\n",
    "        }\n",
    "\n",
    "        substances = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"name\": line[\"Mati√®res\"],\n",
    "            \"cas_number\": \"\",\n",
    "            \"quantity\": \"\",\n",
    "            \"clp_class\" : line[\"Classe de danger CLP\"]\n",
    "        }\n",
    "\n",
    "        consequences_human = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"fatalities\": None,\n",
    "            \"injuries\": None,\n",
    "            \"evacuated\": None,\n",
    "            \"hospitalized\": None,\n",
    "        }\n",
    "\n",
    "        consequences = {\n",
    "            \"ENVIRONNEMENTALES\" : \"\",\n",
    "            \"√âCONOMIQUES\" : \"\"\n",
    "        }\n",
    "\n",
    "        try :\n",
    "            for consequence in line[\"Cons√©quences\"].split(\"CONS√âQUENCES \"):\n",
    "                if len(consequence) < 2 : continue\n",
    "                s = consequence.split(',')\n",
    "                key = s[0]\n",
    "                content = (','.join(s[1:])).removesuffix(',')\n",
    "                consequences[key] = content\n",
    "        except : pass\n",
    "\n",
    "        consequences_other = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"environmental_impact\": consequences[\"ENVIRONNEMENTALES\"],\n",
    "            \"economic_cost\": consequences[\"√âCONOMIQUES\"],\n",
    "            \"disruption_duration\": line[\"Type √©v√®nement\"]\n",
    "        }\n",
    "\n",
    "        tables = {\n",
    "            \"sites\": sites,\n",
    "            \"accidents\": accidents,\n",
    "            \"causes\": causes,\n",
    "            \"substances\": substances,\n",
    "            \"consequences_human\": consequences_human,\n",
    "            \"consequences_other\": consequences_other\n",
    "        }\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    db_lines = []\n",
    "\n",
    "    for x in tqdm(iter(df.iloc), total=trunc, ncols=200):\n",
    "        db_lines.append(create_line(x))\n",
    "\n",
    "    return db_lines\n",
    "\n",
    "ARIA_db_jsons = convert_to_db(df, trunc=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import JSON, display\n",
    "\n",
    "def print_db_jsons(json):\n",
    "    for i, db_line in enumerate(json):\n",
    "        print(i, \"=\" * 200)\n",
    "        for key in db_line :\n",
    "            print(key, flush=True, end='')\n",
    "            display(JSON(db_line[key], expanded=True))\n",
    "        if i == 0 : break\n",
    "\n",
    "print_db_jsons(ARIA_db_jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0156a",
   "metadata": {},
   "source": [
    "# OSHA - Injuries (ITA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5110c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./ITA Case Detail Data 2024 through 08-31-2025.csv\", sep=\",\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bac5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3dbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(df : pd.DataFrame, trunc = None):    \n",
    "\n",
    "    if trunc is not None :\n",
    "        df = df.head(trunc)\n",
    "\n",
    "    def create_line(line : pd.Series):\n",
    "        address = f\"{line['street_address']} {line['city']} {line['state']} {line['zip_code']}\"\n",
    "        site_key = line[\"establishment_name\"] + \" \" + address\n",
    "        site_id = str(uuid5(UUID_NAMESPACE, site_key))\n",
    "        sites = {\n",
    "            \"site_id\" : site_id,\n",
    "            \"plant_name\": line[\"establishment_name\"],  # or fallback to \"company_name\"\n",
    "            \"address\": address,\n",
    "            \"latitude\": None,  # Geocode later from address\n",
    "            \"longitude\": None,\n",
    "            \"country\": \"USA\",\n",
    "            \"industrial_activity\": str(line[\"naics_code\"]),  # Maps to NAF equivalent\n",
    "        }\n",
    "\n",
    "        accident_key = \" \".join([line[\"job_description\"], line[\"date_of_incident\"]])\n",
    "        accident_id = str(uuid5(UUID_NAMESPACE, accident_key))\n",
    "        accidents = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"site_id\": site_id,\n",
    "            \"title\": line[\"job_description\"],  # Brief incident summary\n",
    "            \"source\": \"OSHA ITA\",\n",
    "            \"source_id\": line[\"case_number\"],  # Unique OSHA case identifier\n",
    "            \"accident_date\": line[\"date_of_incident\"],\n",
    "            \"severity_scale\": int(line[\"incident_outcome\"]),  # 1 = Death / 2 = Days away from work / 3 = Job transfer or restriction / 4 = Other recordable case\n",
    "            \"raw_data\": \"\",# line.to_dict(),  # Full line as JSON\n",
    "            \"created_at\": \"date.now()\",\n",
    "            \"updated_at\": \"\",  # Fill on save\n",
    "        }\n",
    "\n",
    "        causes = {\n",
    "            \"accident_id\": accident_id, \n",
    "            \"event_category\": line[\"NEW_NAR_WHAT_HAPPENED\"],  # Deep/root causes\n",
    "            \"equipment_failure\": line[\"NEW_NAR_BEFORE_INCIDENT\"],  # Initial triggers\n",
    "            \"description\": line[\"NEW_INCIDENT_DESCRIPTION\"],\n",
    "        }\n",
    "\n",
    "        substances = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"name\": line[\"NEW_NAR_OBJECT_SUBSTANCE\"],  # Object/substance hit/contacted\n",
    "            \"cas_number\": \"\",  # Not in ITA; research via name if needed\n",
    "            \"quantity\": \"\",  # Derive from context if available\n",
    "            \"clp_class\": line[\"NEW_NAR_INJURY_ILLNESS\"],  # Injury type as hazard proxy\n",
    "        }\n",
    "\n",
    "        consequences_human = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"fatalities\": 1 if pd.notna(line[\"date_of_death\"]) else 0,\n",
    "            \"injuries\": 1,  # Each line is one recordable case\n",
    "            \"evacuated\": None,  # Not directly available\n",
    "            \"hospitalized\": 1 if line[\"dafw_num_away\"] > 0 else 0,  # Days away implies severity\n",
    "        }\n",
    "\n",
    "        consequences_other = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"environmental_impact\": \"\",  # ITA focuses on worker injuries\n",
    "            \"economic_cost\": \"\",  # Estimate from total_hours_worked if needed\n",
    "            \"disruption_duration\": int(line[\"djtr_num_tr\"]),  # Restriction days as proxy\n",
    "        }\n",
    "\n",
    "        tables = {\n",
    "            \"sites\": sites,\n",
    "            \"accidents\": accidents,\n",
    "            \"causes\": causes,\n",
    "            \"substances\": substances,\n",
    "            \"consequences_human\": consequences_human,\n",
    "            \"consequences_other\": consequences_other\n",
    "        }\n",
    "\n",
    "        # taken_cols = [\"Titre\", \"Pays\", \"Code NAF\", \"Num√©ro ARIA\", \"Date\", \"Echelle\", \"Causes profondes\", \"Causes premi√®res\", \"Contenu\", \"Mati√®res\", \"Cons√©quences\", \"D√©partment\", \"Commune\", \"Classe de danger CLP\", \"Type √©v√®nement\"]\n",
    "        # print(line.drop(labels=taken_cols, errors='ignore'))\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    db_lines = []\n",
    "\n",
    "    if trunc is None:\n",
    "        itr = iter(df.iloc)\n",
    "    else :\n",
    "        itr = iter(df.head(trunc).iloc)\n",
    "\n",
    "    for x in tqdm(itr, total=5, ncols=200):\n",
    "        db_lines.append(create_line(x))\n",
    "\n",
    "    return db_lines\n",
    "\n",
    "# OSHA_db_jsons = convert_to_db(df, trunc=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_db_jsons(OSHA_db_jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6272fc4",
   "metadata": {},
   "source": [
    "# EPICEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "epicea_example = {\n",
    "    \"Num√©ro du dossier\": \"27615\",\n",
    "    \"Comit√© technique national\": \"B - B√¢timent et Travaux Publics\",\n",
    "    \"Code entreprise\": \"4321A - Travaux d'installation √©lectrique dans tous locaux\",\n",
    "    \"Mat√©riel en cause\": \"270302 - Chaudi√®re √† mazout\",\n",
    "    \"R√©sum√© de l'accident\": r\"Une √©quipe de trois salari√©s dont un plombier chauffagiste, √¢g√© de 30 ans, intervient chez un particulier, un v√©t√©rinaire dont l'habitation se compose d'une maison et d'un bloc op√©ratoire (achet√©e il y a 21 ans auparavant, maison construite dans les ann√©es 70). L'installation de chauffage de l'habitation, compos√©e d‚Äôune pompe √† chaleur et d‚Äôune chaudi√®re au fioul, alimente les 28 radiateurs de la propri√©t√©. L'alimentation en eau chaude est assur√©e par un ballon d'eau ind√©pendant de l'installation de chauffage. Une chaudi√®re au fioul de la marque *** est plac√©e dans un local √† proximit√© de l'habitation. La chaudi√®re fonctionne en relai de la pompe √† chaleur. Quand la pompe n'arrive plus √† maintenir la consigne de temp√©rature, la chaudi√®re au fioul fonctionne (le propri√©taire de l‚Äôinstallation ne dispose pas du manuel d'utilisation ou d'installation de la chaudi√®re). Le propri√©taire rencontre des difficult√©s sur le fonctionnement de la chaudi√®re au fioul mais ne valide pas le premier devis pour la remplacer. Le second devis propose une remise en √©tat de la chaudi√®re existante avec un d√©sembouage des radiateurs, le remplacement des vannes des radiateurs, l'alimentation entre la cuve de fioul et la chaudi√®re et le ramonage. Ce devis est valid√© par le propri√©taire. Le jour de l‚Äôaccident, l‚Äô√©quipe intervient pour cette prestation approuv√©e. Le plombier chauffagiste r√©alise seul l'entretien de la chaudi√®re dans le local d√©di√© et ses deux coll√®gues r√©alisent le d√©sembouage des radiateurs dans l‚Äôhabitation. Pour r√©aliser le test de combustion, le plombier chauffagiste allume la chaudi√®re. Il met la sonde de l'analyseur de combustion au niveau de l'√©vacuation des fum√©es. Suivant le br√ªleur et les valeurs fournies par l'analyseur, il r√®gle la chaudi√®re. Il est accroupi √† proximit√© de la chaudi√®re. La chaudi√®re explose, le local de la chaudi√®re est envahi de fum√©e et de vapeurs d'eau. A la suite de l‚Äôexplosion, le br√ªleur de la chaudi√®re est au sol devant la chaudi√®re. Il a √©t√© √©ject√©. La trappe d'acc√®s de la chambre de combustion, au-dessus du br√ªleur, est cass√©e sur un angle. A l'int√©rieur de la chambre de combustion, dans le fond, la cuve en fonte pr√©sente un trou. Le plombier chauffagiste se dirige vers la sortie, puis vers le v√©hicule de l'entreprise. Il se regarde dans le r√©troviseur du v√©hicule car son visage le br√ªle. Il constate qu'il n'est pas br√ªl√© sur le visage. Il se d√©shabille lui-m√™me. Son coll√®gue appelle les pompiers. A leur arriv√©e, le plombier est dans la baignoire de l'habitation √† une eau temp√©r√©e, toujours conscient. Il est br√ªl√© par de la vapeur d‚Äôeau sur plus de 50 % du corps aux niveaux des bras, du torse, des parties intimes et des jambes. Hypoth√®ses pour expliquer l‚Äôexplosion de la chaudi√®re : sur le d√©part du r√©seau d'eau de chauffage de la chaudi√®re, il y a des dispositifs de s√©curit√© : un vase d'expansion suivi d'une soupape de s√©curit√©. Le vase d'expansion compense le surplus de volume d'eau quand elle chauffe, il se d√©clenche quand la temp√©rature atteint 60¬∞C. La soupape de s√©curit√© se d√©clenche si la pression atteint les 3 bars. La vanne purge l'eau du circuit pour qu'elle s'√©coule dans le local de la chaudi√®re, hors du r√©seau d'eau de chauffage. Le jour de l'accident, la vanne d‚Äôisolement (entre la chaudi√®re et le r√©seau d‚Äôeau de l‚Äôhabitation pour le chauffage) est ferm√©e. Ce qui permet au plombier chauffagiste de r√©aliser le contr√¥le de combustion sur la chaudi√®re et √† ses coll√®gues de continuer le d√©sembouage sur les radiateurs. Cette vanne est situ√©e avant les dispositifs de s√©curit√© de la chaudi√®re. De ce fait, lorsque le plombier chauffagiste a allum√© la chaudi√®re, la temp√©rature de l'eau augmente ce qui engendre une √©l√©vation de la pression. Les dispositifs de s√©curit√© √©tant situ√©s apr√®s la vanne d'isolement, ils ne se d√©clenchent pas lorsque la temp√©rature et la pression atteignent les valeurs de d√©clenchement. La chaudi√®re continue de chauffer l‚Äôeau jusqu‚Äô√† ce qu‚Äôelle se transforme en vapeur. La pression dans le circuit de la chaudi√®re est telle que la chaudi√®re explose avec la lib√©ration de la vapeur d'eau dans le local.\"\n",
    "}\n",
    "\n",
    "len(epicea_example[\"R√©sum√© de l'accident\"].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ccd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, Any\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import Field\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-5-nano\",\n",
    "    stream_usage=True,\n",
    "    reasoning_effort=\"low\",\n",
    "    service_tier=\"flex\"\n",
    ")\n",
    "\n",
    "SYSTEM_MESSAGE = SystemMessage(content=\"Tu es un assistant fran√ßais. R√©ponds UNIQUEMENT en fran√ßais avec des r√©ponses courtes et pr√©cises. Ne jamais utiliser l'anglais.\" \\\n",
    "            \"Tu es un expert en extraction de donn√©es. Il va t'etre pass√© du text non structur√©, et tu dois le convertir dans la structure donn√©e. \" \\\n",
    "            \"Si un nombre n'est pas mentionn√©, r√©pond 0\")\n",
    "\n",
    "class NumberSchema(BaseModel):\n",
    "    response:int\n",
    "\n",
    "class TextSchema(BaseModel):\n",
    "    response:str\n",
    "\n",
    "class Substance(BaseModel):\n",
    "    \"\"\"Single chemical substance involved in incident.\"\"\"\n",
    "    name: str = Field(..., description=\"Chemical name\")\n",
    "    cas_number: str = Field(..., description=\"CAS registry number\")\n",
    "    quantity: str = Field(..., description=\"Quantity released/spilled\")\n",
    "    clp_class: str = Field(..., description=\"CLP hazard classification\")\n",
    "\n",
    "class SubstancesOutput(BaseModel):\n",
    "    \"\"\"Extracted substances from accident report (0 to many).\"\"\"\n",
    "    response: List[Substance] = Field(default_factory=list, description=\"List of substances\")\n",
    "\n",
    "class DiskCache:\n",
    "    def __init__(self, cache_file: str = \"cache.json\"):\n",
    "        self.cache_file = cache_file\n",
    "        try:\n",
    "            with open(cache_file, 'r') as f:\n",
    "                self.cache: Dict[str, Dict[str, Any]] = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            self.cache = {}\n",
    "    \n",
    "    def get(self, context_hash: str, schema):\n",
    "        if context_hash in self.cache:\n",
    "            data = self.cache[context_hash]\n",
    "            return schema(**data)\n",
    "        return None\n",
    "    \n",
    "    def set(self, context_hash: str, result):\n",
    "        self.cache[context_hash] = result.model_dump()\n",
    "        with open(self.cache_file, 'w') as f:\n",
    "            json.dump(self.cache, f)\n",
    "    \n",
    "    def extract(self, context: str, schema, force_run : bool = False):\n",
    "        context_hash = hashlib.md5(context.encode()).hexdigest()\n",
    "        \n",
    "        if not force_run :\n",
    "            cached = self.get(context_hash, schema)\n",
    "            if cached:\n",
    "                print(f\"‚úÖ Cache HIT for context hash: {context_hash[:8]}\")\n",
    "                return cached\n",
    "        \n",
    "        print(f\"üîÑ Cache MISS - calling API for hash: {context_hash[:8]}\")\n",
    "        \n",
    "        messages = [\n",
    "            SYSTEM_MESSAGE,\n",
    "            HumanMessage(content=context)\n",
    "        ]\n",
    "\n",
    "        structured_llm = llm.with_structured_output(schema, include_raw=True)\n",
    "        result = structured_llm.invoke(messages)\n",
    "        \n",
    "        self.set(context_hash, result[\"parsed\"])\n",
    "        return result[\"parsed\"]\n",
    "\n",
    "context = epicea_example[\"R√©sum√© de l'accident\"]\n",
    "cache = DiskCache()\n",
    "result = cache.extract(f\"Extrait le nombre d'accident√©s de ceci:\\n\\n{context}\", NumberSchema)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c8a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai(field: str, context: str) -> List[Substance] | str:   \n",
    "    prompts = {\n",
    "        \"title\" : {\"prompt\":f\"J'ai besoin d'un titre qui r√©sume en une petite phrase cette description:\\n{context}\", \"schema\": TextSchema},\n",
    "        \"fatalities\" : {\"prompt\":f\"Combien de morts y a t il dans la description suivante:\\n{context}\\n\\n\\nNe r√©pond qu'un seul nombre\", \"schema\": NumberSchema},\n",
    "        \"injuries\" : {\"prompt\":f\"Combien de bless√©s y a t il dans la description suivante:\\n{context}\\n\\n\\nNe r√©pond qu'un seul nombre\", \"schema\": NumberSchema},\n",
    "        \"evacuated\" : {\"prompt\":f\"Combien de personnes √©vacu√©es y a t il dans la description suivante:\\n{context}\\n\\n\\nNe r√©pond qu'un seul nombre\", \"schema\": NumberSchema},\n",
    "        \"hospitalized\" : {\"prompt\":f\"Combien de personnes hospitalis√©es y a t il dans la description suivante:\\n{context}\\n\\n\\nNe r√©pond qu'un seul nombre\", \"schema\": NumberSchema},\n",
    "        \"substances\" : {\"prompt\":f\"Quelles substances sont en jeu dans la description suivante:\\n{context}\\n\\n\\nS'il n'y en a pas r√©pond un JSON vide. Si la quantit√© n'est pas renseign√©e, ne met rien\", \"schema\":SubstancesOutput},\n",
    "    }\n",
    "\n",
    "    if field not in prompts.keys():\n",
    "        return \"<AI> To Prompt\"\n",
    "\n",
    "    selectedPrompt = prompts[field][\"prompt\"]\n",
    "    selectedSchema = prompts[field][\"schema\"]\n",
    "    response = cache.extract(selectedPrompt, selectedSchema).response\n",
    "    \n",
    "    print(field, response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb5396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_db(df : pd.DataFrame, trunc = None):    \n",
    "\n",
    "    if trunc is not None :\n",
    "        df = df.head(trunc)\n",
    "\n",
    "    def create_line(line : pd.Series):\n",
    "        address = \"NULL\"\n",
    "        site_id = str(uuid5(UUID_NAMESPACE, address))\n",
    "        sites = {\n",
    "            \"site_id\" : site_id,\n",
    "            \"plant_name\": \"\",\n",
    "            \"address\": address,\n",
    "            \"latitude\": None,\n",
    "            \"longitude\": None,\n",
    "            \"country\": \"France\",\n",
    "            \"industrial_activity\": line[\"Comit√© technique national\"].split(' - ')[1],\n",
    "        }\n",
    "\n",
    "        CONTEXT_FOR_AI = line[\"R√©sum√© de l'accident\"]\n",
    "        title : str = ask_ai(\"title\", CONTEXT_FOR_AI) # type: ignore\n",
    "\n",
    "        accident_key = \" \".join([title, str(line[\"Num√©ro du dossier\"])])\n",
    "        accident_id = str(uuid5(UUID_NAMESPACE, accident_key))\n",
    "        accidents = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"site_id\": site_id,\n",
    "            \"title\": title,\n",
    "            \"source\": \"EPICEA\",\n",
    "            \"source_id\": str(line[\"Num√©ro du dossier\"]),\n",
    "            \"accident_date\": \"NULL\",\n",
    "            \"severity_scale\": \"NULL\",\n",
    "            \"raw_data\": \"\", #line,\n",
    "            \"created_at\": \"date.now()\",\n",
    "            \"updated_at\": \"\",\n",
    "        }\n",
    "\n",
    "        causes = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"event_category\": line[\"Code entreprise\"].split(' - ')[1],\n",
    "            \"equipment_failure\": line[\"Mat√©riel en cause\"],\n",
    "            \"description\": line[\"R√©sum√© de l'accident\"], \n",
    "        }\n",
    "\n",
    "        substancesOutput : List[Substance] = ask_ai(\"substances\", CONTEXT_FOR_AI) # type: ignore\n",
    "        print(\"============================\", substancesOutput)\n",
    "        substancesArray = []\n",
    "        for substance in substancesOutput :\n",
    "            substanceJSON = {\n",
    "                \"name\":substance.name,\n",
    "                \"cas_number\":substance.cas_number,\n",
    "                \"quantity\":substance.quantity,\n",
    "                \"clp_class\":substance.clp_class\n",
    "            }\n",
    "            substancesArray.append(substanceJSON)\n",
    "        substances = {\"substances\":substancesArray}\n",
    "\n",
    "        consequences_human = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"fatalities\": ask_ai(\"fatalities\", CONTEXT_FOR_AI),\n",
    "            \"injuries\": ask_ai(\"injuries\", CONTEXT_FOR_AI),\n",
    "            \"evacuated\": ask_ai(\"evacuated\", CONTEXT_FOR_AI),\n",
    "            \"hospitalized\": ask_ai(\"hospitalized\", CONTEXT_FOR_AI),\n",
    "        }\n",
    "\n",
    "        consequences_other = {\n",
    "            \"accident_id\": accident_id,\n",
    "            \"environmental_impact\": ask_ai(\"environmental_impact\", CONTEXT_FOR_AI),\n",
    "            \"economic_cost\": ask_ai(\"economic_cost\", CONTEXT_FOR_AI),\n",
    "            \"disruption_duration\": ask_ai(\"disruption_duration\", CONTEXT_FOR_AI)\n",
    "        }\n",
    "\n",
    "        tables = {\n",
    "            \"sites\": sites,\n",
    "            \"accidents\": accidents,\n",
    "            \"causes\": causes,\n",
    "            \"substances\": substances,\n",
    "            \"consequences_human\": consequences_human,\n",
    "            \"consequences_other\": consequences_other\n",
    "        }\n",
    "        \n",
    "        return tables\n",
    "    \n",
    "    db_lines = []\n",
    "\n",
    "    for x in tqdm(iter(df.iloc), total=trunc, ncols=200):\n",
    "        db_lines.append(create_line(x))\n",
    "\n",
    "    return db_lines\n",
    "\n",
    "df = pd.DataFrame(epicea_example, index=[0])\n",
    "EPICEA_db_jsons = convert_to_db(df)\n",
    "print(type(EPICEA_db_jsons))\n",
    "print_db_jsons(EPICEA_db_jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e77b41",
   "metadata": {},
   "source": [
    "# Database Inserting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d644c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_values\n",
    "\n",
    "def insert_jsons_in_db(db_jsons, conn):\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # 1. Insert sites\n",
    "    # Generate an array of tuples without duplicates\n",
    "    constraint_set = set()\n",
    "    sites_tuples = []\n",
    "    for db_json in db_jsons:\n",
    "        constraint_key = db_json[\"sites\"][\"plant_name\"] + db_json[\"sites\"][\"address\"]\n",
    "        if constraint_key in constraint_set : continue\n",
    "        constraint_set.add(constraint_key)\n",
    "\n",
    "        sites_tuples.append((\n",
    "            db_json[\"sites\"][\"site_id\"],\n",
    "            db_json[\"sites\"][\"plant_name\"], \n",
    "            db_json[\"sites\"][\"address\"], \n",
    "            db_json[\"sites\"][\"latitude\"], \n",
    "            db_json[\"sites\"][\"longitude\"], \n",
    "            db_json[\"sites\"][\"country\"], \n",
    "            db_json[\"sites\"][\"industrial_activity\"]\n",
    "        ))\n",
    "\n",
    "    print(\"Inserting sites\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO sites (site_id, plant_name, address, latitude, longitude, country, industrial_activity) VALUES %s ON CONFLICT (plant_name, address) DO NOTHING\"\"\", sites_tuples)\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT site_id, plant_name, address \n",
    "        FROM sites\n",
    "    \"\"\")\n",
    "    all_sites = cur.fetchall()\n",
    "    site_mapping = {(row[1], row[2]): row[0] for row in all_sites}\n",
    "\n",
    "    # Insert accidents  \n",
    "    accidents_tuples = [\n",
    "        (\n",
    "            db_json[\"accidents\"][\"accident_id\"], \n",
    "            site_mapping[(db_json[\"sites\"][\"plant_name\"], db_json[\"sites\"][\"address\"])], \n",
    "            db_json[\"accidents\"][\"title\"], \n",
    "            db_json[\"accidents\"][\"source\"], \n",
    "            db_json[\"accidents\"][\"source_id\"], \n",
    "            db_json[\"accidents\"][\"accident_date\"], \n",
    "            db_json[\"accidents\"][\"severity_scale\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting accidents\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO accidents (accident_id, site_id, title, source, source_id, accident_date, severity_scale) VALUES %s ON CONFLICT DO NOTHING\"\"\", accidents_tuples)\n",
    "\n",
    "    # Insert causes\n",
    "    causes_tuples = [\n",
    "        (\n",
    "            db_json[\"causes\"][\"accident_id\"], \n",
    "            db_json[\"causes\"][\"event_category\"], \n",
    "            db_json[\"causes\"][\"equipment_failure\"], \n",
    "            db_json[\"causes\"][\"description\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting causes\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO causes (accident_id, event_category, equipment_failure, description) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", causes_tuples)\n",
    "\n",
    "    # Insert substances\n",
    "    substances_tuples = [\n",
    "        (\n",
    "            db_json[\"substances\"][\"accident_id\"], \n",
    "            db_json[\"substances\"][\"name\"], \n",
    "            db_json[\"substances\"][\"cas_number\"], \n",
    "            db_json[\"substances\"][\"quantity\"], \n",
    "            db_json[\"substances\"][\"clp_class\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting substances\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO substances (accident_id, name, cas_number, quantity, clp_class) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", substances_tuples)\n",
    "\n",
    "    # Insert human consequences\n",
    "    human_tuples = [\n",
    "        (\n",
    "            db_json[\"consequences_human\"][\"accident_id\"], \n",
    "            db_json[\"consequences_human\"][\"fatalities\"], \n",
    "            db_json[\"consequences_human\"][\"injuries\"], \n",
    "            db_json[\"consequences_human\"][\"evacuated\"], \n",
    "            db_json[\"consequences_human\"][\"hospitalized\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting consequences_human\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO consequences_human (accident_id, fatalities, injuries, evacuated, hospitalized) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", human_tuples)\n",
    "\n",
    "    # Insert other consequences\n",
    "    other_tuples = [\n",
    "        (\n",
    "            db_json[\"consequences_other\"][\"accident_id\"], \n",
    "            db_json[\"consequences_other\"][\"environmental_impact\"], \n",
    "            db_json[\"consequences_other\"][\"economic_cost\"], \n",
    "            db_json[\"consequences_other\"][\"disruption_duration\"]\n",
    "        ) \n",
    "        for db_json in db_jsons\n",
    "    ]\n",
    "    print(\"Inserting consequences_other\")\n",
    "    execute_values(cur, \"\"\"INSERT INTO consequences_other (accident_id, environmental_impact, economic_cost, disruption_duration) VALUES %s ON CONFLICT (accident_id) DO NOTHING\"\"\", other_tuples)\n",
    "\n",
    "    # Commit all inserts\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "\n",
    "conn_string = os.getenv(\"NEON_CONNECTION_STRING\")\n",
    "\n",
    "with psycopg2.connect(conn_string) as conn : \n",
    "    insert_jsons_in_db(ARIA_db_jsons, conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41826ed",
   "metadata": {},
   "source": [
    "# PoC Technique ‚Äî WiseAnalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56862931",
   "metadata": {},
   "source": [
    "# Step 1 - Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c28c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aria = pd.read_csv(\"aria.csv\", sep=\";\")\n",
    "aria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482352a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emars = pd.read_json(\"emars.json\")\n",
    "emars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036a4eb",
   "metadata": {},
   "source": [
    "Le sch√©ma EMARS est d√©j√† tr√®s complet, nous allons donc adapter ARIA √† ce sch√©ma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddec3da",
   "metadata": {},
   "source": [
    "## Adaptation au format EMARS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88a68f",
   "metadata": {},
   "source": [
    "### Normalisation du secteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f8e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize industry sectors between sources\n",
    "\n",
    "industry_mapping = {\n",
    "    'Oil refining': 'Oil Refining',\n",
    "    'Raffinage de p√©trole': 'Oil Refining',\n",
    "    'petroleum storage': 'Oil Storage',\n",
    "    'Stockage hydrocarbures': 'Oil Storage',\n",
    "    'Chemical manufacturing': 'Chemicals',\n",
    "    'Chimie': 'Chemicals',\n",
    "    'Steel production': 'Steel production',\n",
    "    'Sid√©rurgie': 'Steel',\n",
    "    'Petrochemical': 'Petrochemical',\n",
    "    'PETROCHIMIE': 'Petrochemical'\n",
    "}\n",
    "\n",
    "# Check if every value has a mapping\n",
    "# If not, maybe ask an LLM to add it\n",
    "\n",
    "keys = set(industry_mapping.keys())\n",
    "\n",
    "is_aria_subset = set(aria[\"Activite\"]).issubset(keys)\n",
    "if not is_aria_subset : print(\"ARIA misses mapping for\", set(aria[\"Activite\"]).difference(keys))\n",
    "\n",
    "is_emars_subset = set(emars[\"industry_sector\"]).issubset(keys)\n",
    "if not is_emars_subset : print(\"EMARS misses mapping for\", set(emars[\"industry_sector\"]).difference(keys))\n",
    "\n",
    "def map_activite_to_sector(source_activite):\n",
    "    global industry_mapping\n",
    "    return industry_mapping[source_activite]\n",
    "\n",
    "aria[\"Activite\"] = aria[\"Activite\"].apply(map_activite_to_sector)\n",
    "emars[\"industry_sector\"] = emars[\"industry_sector\"].apply(map_activite_to_sector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494440a",
   "metadata": {},
   "source": [
    "### Normalisation des dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_to_iso(source_date):\n",
    "    try : \n",
    "        if \"/\" in source_date:\n",
    "            d = datetime.strptime(source_date, \"%d/%m/%Y\")\n",
    "        elif \"-\" in source_date:\n",
    "            d = datetime.strptime(source_date, \"%Y-%m-%d\")\n",
    "        return d.strftime(\"%Y-%m-%dT00:00:00Z\")\n",
    "    except :\n",
    "        return source_date\n",
    "    \n",
    "aria[\"Date_Accident\"] = aria[\"Date_Accident\"].apply(parse_date_to_iso)\n",
    "emars[\"occurrence_date\"] = emars[\"occurrence_date\"].apply(parse_date_to_iso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b88615",
   "metadata": {},
   "source": [
    "### Extraire les casualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in aria[\"Consequences\"]:\n",
    "    s = x.split(\" - \")\n",
    "    print(s)\n",
    "\n",
    "def extract_casualities(line):\n",
    "    res = {\n",
    "        \"fatalities\":0,\n",
    "        \"injuries\":0\n",
    "    }\n",
    "    for message in line.split(\" - \"):\n",
    "        if \"bless√©\" in message:\n",
    "            if \"Pas\" in message: continue\n",
    "            nb = re.findall(r'\\d+', message)\n",
    "            if len(nb) > 0 : res[\"injuries\"] = int(nb[0])\n",
    "        if \"mort\" in message:\n",
    "            if \"Pas\" in message: continue\n",
    "            nb = re.findall(r'\\d+', message)\n",
    "            if len(nb) > 0 : res[\"fatalities\"] = int(nb[0])\n",
    "    return res\n",
    "\n",
    "aria[\"casualties\"] = aria[\"Consequences\"].apply(extract_casualities)\n",
    "aria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df239a",
   "metadata": {},
   "source": [
    "### Extraire root_causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb118916",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in aria[\"Origine\"]:\n",
    "    print(x)\n",
    "\n",
    "def extract_root_causes(line):\n",
    "    return line.replace(\" + \", \" - \").split(\" - \")\n",
    "\n",
    "aria[\"Origine\"] = aria[\"Origine\"].apply(extract_root_causes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab914082",
   "metadata": {},
   "source": [
    "### Mapping des noms de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9eaf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "aria[\"country\"] = \"FR\"\n",
    "aria_renamed = aria.rename({\"N¬∞ARIA\":\"report_id\", \"Resume\":\"description\", \"Date_Accident\":\"occurrence_date\", \"Activite\":\"industry_sector\", \"Origine\":\"root_causes\"}, axis=1)\n",
    "aria_renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b96b53e",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7b765",
   "metadata": {},
   "source": [
    "Dans le cadre du POC, nous allons partir du principe que :\n",
    "- Le pays suffit a localiser l'incident\n",
    "- Les substances et les impacts environnementaux ne sont pas importants\n",
    "- ARIA ne contient pas de \"Lessons_learned\", mais nous gardons quand meme celles pr√©sentes dans EMARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "aria_cleaned = aria_renamed.drop([\"Commune\", \"Dept\", \"Consequences\"], axis=1)\n",
    "aria_cleaned[\"lessons_learned\"] = None\n",
    "aria_cleaned[\"seveso_tier\"] = None\n",
    "aria_cleaned[\"Source\"] = \"ARIA\"\n",
    "aria_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e04e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "emars_cleaned = emars.drop([\"region\", \"substance_involved\", \"event_type\", \"environmental_impact\"], axis=1)\n",
    "emars_cleaned[\"seveso_tier\"] = emars_cleaned[\"seveso_tier\"].apply(str.upper)\n",
    "emars_cleaned[\"Source\"] = \"EMARS\"\n",
    "emars_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd272b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([emars_cleaned, aria_cleaned])\n",
    "df[['fatalities', 'injuries']] = pd.DataFrame(aria['casualties'].tolist())\n",
    "df = df.drop('casualties', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28dca9d",
   "metadata": {},
   "source": [
    "### Pour aller plus loin, on pourrait :\n",
    "- Traduire le francais en anglais\n",
    "- Cat√©goriser les root_causes, comme pour les industry_sector\n",
    "- Retrouver les substances et les impacts environnementaux dans la description des √©v√©nements ARIA via LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827df01",
   "metadata": {},
   "source": [
    "# Step 3 - Prototype RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "input_columns = df.columns\n",
    "\n",
    "def prepare_rag_data(df):\n",
    "    df = df.copy()\n",
    "    df['rag_text'] = (\n",
    "        df['industry_sector'] + \" | \" +\n",
    "        df['occurrence_date'].astype(str) + \" | \" +\n",
    "        df['country'] + \" | \" +\n",
    "        df['description'].fillna('') + \" | \"\n",
    "        # df['root_causes'].astype(str) + \" | \" +\n",
    "        # df['lessons_learned'].fillna('') + \" | \" +\n",
    "        # df['Source']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def parse_client(df):\n",
    "    df[\"country\"] = \"FR\"\n",
    "    df['industry_sector'] = \"Petrochemical\"\n",
    "    df[\"occurrence_date\"] = df[\"date\"].apply(parse_date_to_iso)\n",
    "    df[\"root_causes\"] = df[\"root_cause_preliminary\"]\n",
    "    if \"fatalities\" not in df.columns : df[\"fatalities\"] = 0\n",
    "    return df\n",
    "\n",
    "class HybridRAG:\n",
    "    def __init__(self, df_public, client_docs_path):\n",
    "        self.df_public = prepare_rag_data(df_public)\n",
    "        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        self.df_client = pd.read_json(client_docs_path)\n",
    "        self.df_client['Source'] = 'CLIENT_INTERNE'\n",
    "        self.df_client = parse_client(self.df_client)\n",
    "\n",
    "        for col in input_columns :\n",
    "            if col not in self.df_client.columns:\n",
    "                print(\"Missing col in client data :\", col)\n",
    "                self.df_client[col] = None\n",
    "\n",
    "        self.df_client = prepare_rag_data(self.df_client)\n",
    "        \n",
    "        all_texts = self.df_public['rag_text'].tolist() + self.df_client['rag_text'].tolist()\n",
    "        self.all_embeddings = self.model.encode(all_texts, show_progress_bar=True)\n",
    "        \n",
    "        self.public_count = len(self.df_public)\n",
    "    \n",
    "    def search(self, query, k=5):\n",
    "        query_emb = self.model.encode([query])\n",
    "        similarities = cosine_similarity(query_emb, self.all_embeddings)[0]\n",
    "\n",
    "        top_indices = np.argsort(similarities)[::-1][:k*2]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            score = similarities[idx]\n",
    "            \n",
    "            if idx < self.public_count: # Base publique\n",
    "                row = self.df_public.iloc[idx]\n",
    "                source_type = \"PUBLIC\"\n",
    "            else: # Documents internes\n",
    "                row = self.df_client.iloc[idx - self.public_count]\n",
    "                source_type = \"CLIENT\"\n",
    "            \n",
    "            result = {\n",
    "                'score': f\"{score:.3f}\",\n",
    "                'source_type': source_type,\n",
    "                'report_id': row['report_id'],\n",
    "                'date': row['occurrence_date'],\n",
    "                'country': row['country'],\n",
    "                'industry': row['industry_sector'],\n",
    "                'description': row['description'],\n",
    "                'root_causes': row['root_causes'],\n",
    "                'fatalities': row['fatalities'],\n",
    "                'injuries': row['injuries'],\n",
    "                'source': row['Source']\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return results[:k]  # Top K final\n",
    "\n",
    "def demo_hybrid_rag(df_public):    \n",
    "    rag = HybridRAG(df_public, \"client-internal-incidents.json\")\n",
    "    \n",
    "    questions = [\n",
    "        \"Quels accidents impliquant des fuites de gaz ont eu lieu dans le secteur petrochimique ?\",\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"\\nüìä QUESTION {i}: {question}\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        results = rag.search(question, k=5)\n",
    "        \n",
    "        for j, res in enumerate(results, 1):\n",
    "            print(f\"{j:2d}. [{res['score']}] <{res['source_type']}>\")\n",
    "            print(f\"    {res['country']} | {res['industry']} | {res['date']}\")\n",
    "            print(f\"    {res['description']}...\")\n",
    "            print(f\"       {res['fatalities']} morts, {res['injuries']} bless√©s\")\n",
    "            print()\n",
    "\n",
    "demo_hybrid_rag(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
